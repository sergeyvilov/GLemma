{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da6f45f6-3a1d-4659-9ae1-9c08295a7754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('max_colwidth', 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "001eacf1-26d4-4318-90cb-9d6c8fc1e5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_verb_lemma_morpho(word, query_verb_dict_fnc, prefixes_list, use_longest_subword=True):\n",
    "\n",
    "    def get_verb_lemma_recursive(word, morphemes=[]):\n",
    "        '''\n",
    "        Recursively detect prefixes and yield all possible lemmas\n",
    "        '''\n",
    "        res = []\n",
    "        \n",
    "        base_lemma = query_verb_dict_fnc(word)\n",
    "        \n",
    "        if base_lemma:\n",
    "            #print(word,morphemes,base_lemma)\n",
    "            if len(morphemes)>1 and morphemes[-1] == 'zu' and base_lemma == word:\n",
    "                #suspect a zu-infinitive: some prefix on the right + zu + infinitive\n",
    "                #e.g. abzuheben, aufzuatmen\n",
    "                res.append((''.join(morphemes[:-1]+[base_lemma]),word)) #add without \"zu\"\n",
    "            else:\n",
    "                res.append((''.join(morphemes+[base_lemma]),word)) #compose the infinitive out of the collected prefixes and the base lemma\n",
    "                \n",
    "        for prefix_end_idx in range(1,len(word)-2):\n",
    "            #look for the next prefix which ends at prefix_end_idx\n",
    "            if word[:prefix_end_idx] in prefixes_list:\n",
    "                #prefix in the list of known prefixes\n",
    "                prefix = word[:prefix_end_idx] \n",
    "                res.extend(get_verb_lemma_recursive(word[prefix_end_idx:], morphemes+[prefix])) #detach the prefix, call the function again\n",
    "    \n",
    "        return res\n",
    "        \n",
    "    lemmas = get_verb_lemma_recursive(word)\n",
    "\n",
    "    if lemmas:\n",
    "        lemmas.sort(key=lambda x:-len(x[1])) #sort according to subword length, ascending=False\n",
    "        lemmas, subwords = zip(*lemmas)     \n",
    "        if (use_longest_subword or len(set(lemmas))==1):\n",
    "        #all possible splits lead to the same lemma or taking the longest subword allowed\n",
    "            return lemmas[0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23351203-fff8-4e1f-9257-73426b6719e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noun_lemma_fwdsearch(word, query_noun_dict_fnc, use_longest_subword=True):\n",
    "\n",
    "    '''\n",
    "    Get all possible noun lemmas using forward search\n",
    "    '''\n",
    "\n",
    "    lemmas = []\n",
    "    \n",
    "    for start_idx in range(0,len(word)-2):\n",
    "        #remove letters one by one, until the rest of the word matches one in the vocabulary\n",
    "        trial_word = word[start_idx:]\n",
    "        base_lemma = query_noun_dict_fnc(trial_word)\n",
    "        if base_lemma:\n",
    "            #print(word[0:start_idx] + base_lemma, base_lemma)\n",
    "            lemmas.append(word[0:start_idx] + base_lemma)\n",
    "\n",
    "    if lemmas and (use_longest_subword or len(set(lemmas))==1):\n",
    "        #all possible splits lead to the same lemma or taking the longest subword allowed\n",
    "        return lemmas[0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cd3461f-1e3b-4cbd-84c3-9f214db22a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_verb_lemma_fwdsearch(word, query_verb_dict_fnc, use_longest_subword=True):\n",
    "\n",
    "    '''\n",
    "    Get all possible verb lemmas using forward search, prefix-agnostic\n",
    "    '''\n",
    "\n",
    "    lemmas = []\n",
    "    \n",
    "    for start_idx in range(0,len(word)-2):\n",
    "        #remove letters one by one, until the rest of the word matches one in the vocabulary\n",
    "        trial_word = word[start_idx:]\n",
    "        base_lemma = query_verb_dict_fnc(trial_word)\n",
    "        if start_idx>2 and word[start_idx-2:start_idx] == 'zu' and base_lemma == trial_word:\n",
    "            #suspect a zu-infinitive: some prefix on the right + zu + infinitive\n",
    "            #e.g. abzuheben, aufzuatmen\n",
    "            lemmas.append(word[0:start_idx-2] + base_lemma) #add without \"zu\"\n",
    "        elif base_lemma and not base_lemma.startswith('zu'):\n",
    "            lemmas.append(word[0:start_idx] + base_lemma)\n",
    "\n",
    "    if lemmas and (use_longest_subword or len(set(lemmas))==1):\n",
    "        #all possible splits lead to the same lemma or taking the longest subword allowed\n",
    "        return lemmas[0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e397222c-2774-413e-a6db-67d67cd7f492",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_constraints = {'dieser': (('f', 'Genitiv Singular'), ('n', 'Genitiv Plural'), ('m', 'Genitiv Plural'), ('m', 'Nominativ Singular'), ('f', 'Dativ Singular'), ('f', 'Genitiv Plural'), ('only_plural', 'Genitiv Plural')), \n",
    " 'der': (('f', 'Genitiv Singular'), ('n', 'Genitiv Plural'), ('m', 'Genitiv Plural'), ('m', 'Nominativ Singular'), ('f', 'Dativ Singular'), ('f', 'Genitiv Plural'), ('only_plural', 'Genitiv Plural')), \n",
    " 'kein': (('m', 'Nominativ Singular'), ('n', 'Nominativ Singular'), ('n', 'Akkusativ Singular')), \n",
    " 'dieses': (('n', 'Nominativ Singular'), ('n', 'Akkusativ Singular'), ('m', 'Genitiv Singular'), ('n', 'Genitiv Singular')), \n",
    " 'des': (('m', 'Genitiv Singular'), ('n', 'Genitiv Singular')), 'keines': (('m', 'Genitiv Singular'), ('n', 'Genitiv Singular')), \n",
    " 'diesem': (('n', 'Dativ Singular'), ('m', 'Dativ Singular')), 'dem': (('n', 'Dativ Singular'), ('m', 'Dativ Singular')), \n",
    " 'keinem': (('n', 'Dativ Singular'), ('m', 'Dativ Singular')), 'diesen': (('n', 'Dativ Plural'), ('only_plural', 'Dativ Plural'), ('f', 'Dativ Plural'), ('m', 'Akkusativ Singular'), ('m', 'Dativ Plural')), \n",
    " 'den': (('n', 'Dativ Plural'), ('only_plural', 'Dativ Plural'), ('f', 'Dativ Plural'), ('m', 'Akkusativ Singular'), ('m', 'Dativ Plural')), \n",
    " 'keinen': (('n', 'Dativ Plural'), ('only_plural', 'Dativ Plural'), ('f', 'Dativ Plural'), ('m', 'Akkusativ Singular'), ('m', 'Dativ Plural')), \n",
    " 'die': (('only_plural', 'Nominativ Plural'), ('n', 'Akkusativ Plural'), ('f', 'Akkusativ Singular'), ('only_plural', 'Akkusativ Plural'), ('f', 'Nominativ Singular'), ('m', 'Nominativ Plural'), ('m', 'Akkusativ Plural'), ('f', 'Nominativ Plural'), ('n', 'Nominativ Plural'), ('f', 'Akkusativ Plural')), \n",
    " 'diese': (('only_plural', 'Nominativ Plural'), ('n', 'Akkusativ Plural'), ('f', 'Akkusativ Singular'), ('only_plural', 'Akkusativ Plural'), ('f', 'Nominativ Singular'), ('m', 'Nominativ Plural'), ('m', 'Akkusativ Plural'), ('f', 'Nominativ Plural'), ('n', 'Nominativ Plural'), ('f', 'Akkusativ Plural')), \n",
    " 'keine': (('only_plural', 'Nominativ Plural'), ('n', 'Akkusativ Plural'), ('f', 'Akkusativ Singular'), ('only_plural', 'Akkusativ Plural'), ('f', 'Nominativ Singular'), ('m', 'Nominativ Plural'), ('m', 'Akkusativ Plural'), ('f', 'Nominativ Plural'), ('n', 'Nominativ Plural'), ('f', 'Akkusativ Plural')), \n",
    " 'keiner': (('f', 'Genitiv Singular'), ('f', 'Genitiv Plural'), ('m', 'Genitiv Plural'), ('f', 'Dativ Singular'), ('n', 'Genitiv Plural'), ('only_plural', 'Genitiv Plural')), 'das': (('n', 'Nominativ Singular'), ('n', 'Akkusativ Singular'))\n",
    "}\n",
    "\n",
    "prep_constraints = {\n",
    "                 'zu': (('m','Dativ Singular'),('n','Dativ Singular'),('f','Dativ Singular'),('m','Dativ Plural'),('n','Dativ Plural'),('f','Dativ Plural')),\n",
    "                 'von': (('m','Dativ Singular'),('n','Dativ Singular'),('f','Dativ Singular'),('m','Dativ Plural'),('n','Dativ Plural'),('f','Dativ Plural')),\n",
    "                 'bei': (('m','Dativ Singular'),('n','Dativ Singular'),('f','Dativ Singular'),('m','Dativ Plural'),('n','Dativ Plural'),('f','Dativ Plural')),\n",
    "                 'durch': (('m','Akkusativ Singular'),('n','Akkusativ Singular'),('f','Akkusativ Singular'),('m','Akkusativ Plural'),('n','Akkusativ Plural'),('f','Akkusativ Plural')),\n",
    "                 'für': (('m','Akkusativ Singular'),('n','Akkusativ Singular'),('f','Akkusativ Singular'),('m','Akkusativ Plural'),('n','Akkusativ Plural'),('f','Akkusativ Plural')),\n",
    "                 'um': (('m','Akkusativ Singular'),('n','Akkusativ Singular'),('f','Akkusativ Singular'),('m','Akkusativ Plural'),('n','Akkusativ Plural'),('f','Akkusativ Plural')),\n",
    "                 'im':(('m','Dativ Singular'),('n','Dativ Singular')),\n",
    "                 'beim':(('m','Dativ Singular'),('n','Dativ Singular')),\n",
    "                 'zum':(('m','Dativ Singular'),('n','Dativ Singular')),\n",
    "                 'vom':(('m','Dativ Singular'),('n','Dativ Singular')),\n",
    "                 'zur':(('f','Dativ Singular'),),\n",
    "                 'hintern':(('m','Akkusativ Singular'),),\n",
    "                 'übern':(('m','Akkusativ Singular'),),\n",
    "                 'untern':(('m','Akkusativ Singular'),),\n",
    "                 'ins':(('n','Akkusativ Singular'),),\n",
    "                 'aufs':(('n','Akkusativ Singular'),),\n",
    "                 'durchs':(('n','Akkusativ Singular'),),\n",
    "                 'fürs':(('n','Akkusativ Singular'),),\n",
    "                 'ums':(('n','Akkusativ Singular'),),\n",
    "                 'vors':(('n','Akkusativ Singular'),),\n",
    "                 'übers':(('n','Akkusativ Singular'),),\n",
    "                 'unters':(('n','Akkusativ Singular'),),\n",
    "                 'hinterm':(('m','Dativ Singular'),('n','Dativ Singular')),\n",
    "                 'überm':(('m','Dativ Singular'),('n','Dativ Singular')),\n",
    "                 'unterm':(('m','Dativ Singular'),('n','Dativ Singular')),\n",
    "                 'vorm':(('m','Dativ Singular'),('n','Dativ Singular')),\n",
    "                }\n",
    "\n",
    "def get_base_determiner(word):\n",
    "    '''\n",
    "    Check if a given word is a determiner and return the base form\n",
    "    '''\n",
    "    kein_style = re.match(r'(mein|dein|sein|ihr|Ihr|euer|unser|ein|kein|welch|solch|manch)($|e[rsnm]?$)',word)\n",
    "    if kein_style:\n",
    "        return 'kein'+kein_style.groups()[1]\n",
    "    der_form = re.match(r'(der|die|das|dem|den|des)$',word)\n",
    "    if der_form:\n",
    "        return word\n",
    "    der_style = re.match(r'(diese|jede|jene)([rsnm]?$)',word)\n",
    "    if der_style:\n",
    "        return 'diese'+der_style.groups()[1]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddb936ce-de41-4d83-96b5-698aedef2fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NounsNBC():\n",
    "\n",
    "    def __init__(self, path):\n",
    "\n",
    "        with open(path,'rb') as f:\n",
    "\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "            self.nbc_clf = data['clf']\n",
    "            self.features_encoder = data['features_encoder']\n",
    "            self.features_list = data['features_list']\n",
    "            self.rules_list = data['rules_list']\n",
    "            self.n_last = data['n_last']\n",
    "        \n",
    "    def __call__(self, word, constraints=None):\n",
    "        \n",
    "        word_parts = [word[idx:] for idx in range(-self.n_last,0)]\n",
    "\n",
    "        if not constraints:\n",
    "            constraints = ((-1,-1),)\n",
    "\n",
    "        data = [word_parts+list(constraint) for constraint in constraints]\n",
    "\n",
    "        word_enc = self.features_encoder.transform(data).astype(int)\n",
    "        \n",
    "        if len(constraints)==1:\n",
    "\n",
    "            pred = self.nbc_clf.predict(word_enc)[0]\n",
    "            \n",
    "        else:\n",
    "                        \n",
    "            pred = self.nbc_clf.predict_proba(word_enc).mean(0).argmax()\n",
    "        \n",
    "        rule = self.rules_list[pred]\n",
    "    \n",
    "        if rule=='-':\n",
    "            return None\n",
    "        else:\n",
    "            seq_to_remove,seq_to_add = rule\n",
    "            return re.sub(f'{seq_to_remove}$',seq_to_add,word)\n",
    "            \n",
    "        return None\n",
    "\n",
    "class CategoricalNaiveBayes():\n",
    "\n",
    "    def __init__(self, kappa=2, epsilon=1e-20):\n",
    "        \n",
    "        self.kappa = kappa\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def _compute_priors_logprobs(self, y):\n",
    "\n",
    "        priors_probs = [class_counts/len(y) for class_counts in self.class_counts]\n",
    "\n",
    "        self.priors_logprobs = np.log(priors_probs)\n",
    "        \n",
    "    def _compute_loglikelihood(self, X, y):\n",
    "        \n",
    "        feature_counts = {feature_idx:np.zeros((self.n_categories[feature_idx]+2,self.n_classes)) for feature_idx in range(self.n_features)}\n",
    "        \n",
    "        for features, class_idx in zip(X, y):\n",
    "            \n",
    "            for feature_idx,feature_value in enumerate(features):\n",
    "                \n",
    "                feature_counts[feature_idx][feature_value,class_idx] += 1\n",
    "\n",
    "        loglikelihood = {feature_idx:np.zeros((self.n_categories[feature_idx]+2,self.n_classes)) for feature_idx in range(self.n_features)}\n",
    "\n",
    "        for feature_idx in range(self.n_features):\n",
    "            loglikelihood[feature_idx] = np.log((feature_counts[feature_idx]+self.epsilon)\n",
    "                                                          / (np.repeat(self.class_counts[None,...], self.n_categories[feature_idx]+2, axis=0)\n",
    "                                                            + self.kappa*self.epsilon))\n",
    "\n",
    "            loglikelihood[feature_idx][-1,:] = 0\n",
    "\n",
    "        self.loglikelihood = loglikelihood\n",
    "\n",
    "        \n",
    "    def fit(self, X_train, y_train, priors_logprobs=None):\n",
    "\n",
    "        counter = Counter(y_train)\n",
    "        \n",
    "        class_ids, class_counts = zip(*sorted(counter.items()))\n",
    "        \n",
    "        self.class_counts = np.array(class_counts)\n",
    "        self.n_classes = np.max(class_ids)+1\n",
    "\n",
    "        self.n_features = X_train.shape[1]\n",
    "        self.n_categories = X_train.max(axis=0)\n",
    "\n",
    "        if priors_logprobs is None:\n",
    "            self._compute_priors_logprobs(y_train)\n",
    "        else:\n",
    "            self.priors_logprobs = priors_logprobs\n",
    "\n",
    "        self._compute_loglikelihood(X_train, y_train)\n",
    "\n",
    "    def _get_bayes_numerator(self, X):\n",
    "\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        sample_loglikelihood = np.zeros((n_samples,self.n_features,self.n_classes))\n",
    "\n",
    "        for feature_idx in range(self.n_features):\n",
    "            \n",
    "            sample_loglikelihood[:,feature_idx,:] = self.loglikelihood[feature_idx][X[:,feature_idx]] #N_samplesxN_classes\n",
    "\n",
    "        numerator = sample_loglikelihood.sum(axis=1)  + self.priors_logprobs[None,...]\n",
    "\n",
    "        return numerator\n",
    "            \n",
    "    def predict_proba(self, X):\n",
    "\n",
    "        numerator = np.exp(self._get_bayes_numerator(X))\n",
    "        \n",
    "        probs = numerator/numerator.sum(axis=1,keepdims=True)\n",
    "                            \n",
    "        return probs\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        predicted_class_ids = self._get_bayes_numerator(X).argmax(1)\n",
    "\n",
    "        return predicted_class_ids\n",
    "        \n",
    "    def score(self, X, y):\n",
    "\n",
    "        y_pred = self.predict(X)\n",
    "\n",
    "        return (y_pred==np.array(y)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd5c22a6-b19e-4762-aeb9-9c507eb274ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.26.0'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3d26b79-4d9e-4d7d-8d2b-10983c3b1c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NounsStatRules():\n",
    "\n",
    "    def __init__(self, path):\n",
    "\n",
    "        with open(path,'rb') as f:\n",
    "            \n",
    "            data = pickle.load(f)\n",
    "            \n",
    "            self.rules_dict = data['rules_dict']\n",
    "            self.n_last = data['n_last']\n",
    "            \n",
    "    def __call__(self,word):\n",
    "\n",
    "        for idx in range(-self.n_last,0):\n",
    "            rule =  self.rules_dict[f'last_{abs(idx)}'].get(word[idx:],None)\n",
    "            if rule:\n",
    "                seq_to_remove,seq_to_add = rule\n",
    "                return re.sub(f'{seq_to_remove}$',seq_to_add,word)\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b304527-c0d6-424c-948b-56a3371c5b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLemma():\n",
    "\n",
    "    \"\"\"Wiktionary-based German lemmatizer.\n",
    "\n",
    "    Provides a lemma for a given word given the POS tag:\n",
    "    NOUN, VERB, ADJ, ADV.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lemmatizer_data_path : str\n",
    "        Data path to the lemmatizer files.\n",
    "\n",
    "    use_nouns_nbc : bool, default=False\n",
    "        Use Naive Bayes classifier for unknown nouns.\n",
    "        Slow (not suitable for annotating large corpora), but precise.\n",
    "\n",
    "    nouns_statrules_acc : int, default=95\n",
    "        Accuracy for statistical tables, can be (95, 99, 100) \n",
    "        When use_nouns_nbc=False, statistical tables are used for unknown nouns to get a lemma based on the ending.\n",
    "\n",
    "    guess_adj_lemmas : bool, default=True\n",
    "        Guess adjective lemmas based on most common endings\n",
    "\n",
    "    wordfreq_csv : str, default=None\n",
    "        A file with approximate word frequencies. \n",
    "        The file must have 2 tab-separated columns for words and their number of occurrences in a corpus.\n",
    "        When multiple lemmas for a given word form are possible, the most frequent lemma is taken.\n",
    "        Does not have to be a lemma list.\n",
    "        \n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> lemmatizer = GLemma('./data', \n",
    "                    wordfreq_csv='data/third-party/FrequencyWords/content/2018/de/de_full.txt')\n",
    "    >>> lemmatizer('vermalt','VERB')\n",
    "    'vermalen'\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    If a verb prefix is separated in the sentence, it should be attached to the root before the lemmatization:\n",
    "    Ich hole dich ab --> lemmatizer('abhole','VERB')\n",
    "\n",
    "    By setting nouns_statrules_acc=100, use_nouns_nbc=False,guess_adj_lemmas=False, and wordfreq_csv=None, the lemmatizer only returns\n",
    "    lemmas that it's 100% sure about.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lemmatizer_data_path, use_nouns_nbc=False, nouns_statrules_acc = 95, guess_adj_lemmas=True, wordfreq_csv=None):\n",
    "\n",
    "\n",
    "        with open(os.path.join(lemmatizer_data_path,'vocab.json'), 'rt', encoding='UTF-8') as json_file:\n",
    "            self.vocab = json.load(json_file)\n",
    "\n",
    "        if use_nouns_nbc:\n",
    "            self.nouns_nbc = NounsNBC(os.path.join(lemmatizer_data_path,'nouns-nbc-top100.pickle'))\n",
    "        else:\n",
    "            self.nouns_nbc = None\n",
    "\n",
    "        self.nouns_stat_rules = NounsStatRules(os.path.join(lemmatizer_data_path,f'nouns_stat_rules-{nouns_statrules_acc}.pickle'))\n",
    "    \n",
    "        if wordfreq_csv:\n",
    "            self.wordfreq = pd.read_csv(wordfreq_csv, sep=' ', names=['word','freq'])\n",
    "            self.wordfreq.word = self.wordfreq.word.str.lower()\n",
    "            self.wordfreq = self.wordfreq.set_index('word').freq.sort_values(ascending=False) #sort by frequency\n",
    "            self.wordfreq = self.wordfreq.to_dict()\n",
    "        else:\n",
    "            self.wordfreq = None\n",
    "\n",
    "        self.guess_adj_lemmas = guess_adj_lemmas\n",
    "\n",
    "    def get_most_frequent_word(self, wordlist):\n",
    "        '''\n",
    "        Get the most frequent word out of wordlist\n",
    "        '''\n",
    "        \n",
    "        if self.wordfreq:\n",
    "            freqs = [self.wordfreq.get(word, np.nan) for word in wordlist]\n",
    "            if all(np.isnan(freqs)):\n",
    "                return None\n",
    "            else:\n",
    "                #if at least one word in the wordrank dictionary\n",
    "                return wordlist[np.nanargmax(freqs)]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def get_noun_constraints(self, spacy_token):\n",
    "        '''\n",
    "        Get noun constraints in the form (genus, declination) based on the preceeding articles or preposition\n",
    "        e.g. if the noun preceeded by 'durchs' the constraint is ('n','Akkusativ Singular')\n",
    "        multiple constraints are possible\n",
    "        '''\n",
    "\n",
    "        if spacy_token is None:\n",
    "            return None\n",
    "        \n",
    "        ancestors_lemmas = [x.text.lower() for x in spacy_token.ancestors] #hope to find prepositions here, can be fused with articles, e.g. im, durchs\n",
    "        for ancestors_lemma in ancestors_lemmas:\n",
    "            ancestors_constraints = prep_constraints.get(ancestors_lemma, None)\n",
    "            if ancestors_constraints:\n",
    "                return ancestors_constraints\n",
    "            \n",
    "        childeren_lemmas = [x.text.lower() for x in spacy_token.children] #hope to find determiners here, e.g. der, diese, etc.\n",
    "        for childeren_lemma in childeren_lemmas:\n",
    "            base_determiner = get_base_determiner(childeren_lemma)#convert determiners to canonical form\n",
    "            if base_determiner: \n",
    "                return article_constraints[base_determiner]\n",
    "                \n",
    "        return None\n",
    "\n",
    "    def filter_verb_lemmas(self, lemmas, spacy_token):\n",
    "\n",
    "        if spacy_token is None:\n",
    "            return None\n",
    "            \n",
    "        if spacy_token.head.lemma_ in ('haben','sein'):\n",
    "            #Perfekt suspected\n",
    "            n_hilfsverb = len(set([y for x in lemmas for y in x['via']]))\n",
    "            if n_hilfsverb>1: #do we really have to choose between sein and haben?\n",
    "                lemmas = [x for x in lemmas if x['connection']=='Partizip II' \n",
    "                          #token head should match the auxiliary verb\n",
    "                                    and spacy_token.head.lemma_ in x['via']]\n",
    "        elif spacy_token.head.lemma_=='werden':\n",
    "            #werden is an auxiliary verb for Passiv or Futur, \n",
    "            #the wordform should be Partizip II (Passiv) or the same as lemma (Futur)\n",
    "            lemmas = [x for x in lemmas if x['connection']=='Partizip II' \n",
    "                                or x['lemma']==spacy_token.text.lower()]\n",
    "        else:\n",
    "            #no evidence for Perfekt or Passiv, so the wordform can't be Partizip II\n",
    "            lemmas = [x for x in lemmas if not x['connection']=='Partizip II']\n",
    "\n",
    "        return lemmas\n",
    "            \n",
    "    def get_word_lemma(self, word, pos, spacy_token=None):\n",
    "\n",
    "        lemmas = self.vocab[pos].get(word, None)   \n",
    "\n",
    "        if not lemmas:\n",
    "            #maybe old orthography? try to replace ß with ss at the end of the stem \n",
    "            newform=re.sub(r'ß($|es$|t?en$|t?e$|t?e?t$|t?est$)',r'ss\\1', word) \n",
    "            lemmas = self.vocab[pos].get(newform, None)   \n",
    "\n",
    "        if not lemmas:\n",
    "            return None\n",
    "            \n",
    "        n_unique_lemmas = len(set([x['lemma'] for x in lemmas])) #count unique lemmas, e.g. 'konzentriert' will have 2 records: one for the infinitive and one for the Partizip II\n",
    "        \n",
    "        if n_unique_lemmas>1 and spacy_token:\n",
    "\n",
    "            #multiple lemmas possible for this wordform\n",
    "            #use Spacy dependency parcer to reduce the possibilities\n",
    "\n",
    "            if pos=='N':\n",
    "                #look for noun constraints, e.g. a related article imposes a particular declination, thus a particular wordform\n",
    "                constraints = self.get_noun_constraints(spacy_token)\n",
    "                \n",
    "                if constraints:\n",
    "                    lemmas = [lemma for lemma in lemmas if (lemma['genus'],lemma['declination']) in constraints]\n",
    "                \n",
    "            elif pos=='V':\n",
    "                lemmas = self.filter_verb_lemmas(lemmas, spacy_token)\n",
    "                \n",
    "        lemmas = list(set([x['lemma'] for x in lemmas])) #remove all meta info, take unique words\n",
    "        \n",
    "        if not lemmas:\n",
    "            return None\n",
    "            \n",
    "        elif len(lemmas)>1:\n",
    "            #get most frequent lemma, can be very imprecise for frequency dictionaries computed on small datasets \n",
    "            return self.get_most_frequent_word(lemmas)\n",
    "            \n",
    "        else:\n",
    "            return lemmas[0]\n",
    "\n",
    "    def __call__(self, word=None, pos=None, spacy_token=None):\n",
    "\n",
    "        lemma = None\n",
    "\n",
    "        if not word:\n",
    "            word, pos = spacy_token.text, spacy_token.pos_\n",
    "\n",
    "        word = word.lower()\n",
    "\n",
    "        for pos_tag in ('N','V','ADJ','ADV'):\n",
    "            #conver pos to unified pos_tag\n",
    "            if pos.startswith(pos_tag):\n",
    "                pos = pos_tag\n",
    "\n",
    "        if not pos in ('N','V','ADJ','ADV'):\n",
    "            #lemmatizer works only for nouns, verbs, adjectives, and adverbs\n",
    "            return None\n",
    "\n",
    "        if pos=='ADV':\n",
    "            #first treat adverb as an adjective\n",
    "            #because Wiktionary dictionary for adverbs is incomplete and almost any adjective in German can be used as an adverb\n",
    "            lemma = self.get_word_lemma(word, 'ADJ')\n",
    "\n",
    "        if not lemma:\n",
    "            lemma = self.get_word_lemma(word, pos, spacy_token=spacy_token)\n",
    "\n",
    "        if not lemma:\n",
    "            if pos=='N':\n",
    "                if self.nouns_nbc:\n",
    "                    #Naive Bayes classifier: slow, but precise\n",
    "                    constraints = self.get_noun_constraints(spacy_token)\n",
    "                    lemma = self.nouns_nbc(word, constraints)\n",
    "                else:\n",
    "                    #statistical tables to predict lemma based on endings\n",
    "                    lemma = self.nouns_stat_rules(word)\n",
    "            elif pos=='V':\n",
    "                    #look for known lemma at the end of the word\n",
    "                    lemma = get_verb_lemma_fwdsearch(word, lambda x:self.get_word_lemma(x, pos, spacy_token=spacy_token), \n",
    "                                                     use_longest_subword=True)\n",
    "            elif pos in 'ADJ' and self.guess_adj_lemmas:\n",
    "                    #assume most common adjective endings\n",
    "                    lemma = re.sub('e[rsnm]?$','',word)\n",
    "                \n",
    "        if pos=='N' and lemma:\n",
    "            #noun lemmas starts with a capital\n",
    "            lemma = lemma.title()\n",
    "            \n",
    "        return lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1569d82a-c9cb-42a4-995b-aeb96b7a2c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = GLemma('./glemma/data', \n",
    "                    wordfreq_csv='glemma/data/third-party/FrequencyWords/content/2018/de/de_full.txt',\n",
    "                    use_nouns_nbc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992e2884-8e9e-49f3-bdf3-eea5e8fec11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spacy_model(language='en'):\n",
    "\n",
    "    import spacy\n",
    "\n",
    "    language = {\n",
    "        'en': 'en_core_web_lg',\n",
    "        'fr': 'french',\n",
    "        'de': 'de_core_news_lg',\n",
    "    }[language]\n",
    "    return spacy.load(language) \n",
    "\n",
    "spacy_model = get_spacy_model('de')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4a6640-3dce-4710-91e5-f9fe0e7a2556",
   "metadata": {},
   "source": [
    "## Test TIGER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fed9cd5-e63e-4c03-9263-9a0fc0ca5731",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiger_dataset = 'data/third-party/tiger_release_aug07.corrected.16012013.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "537b4358-a37c-41ea-a064-684bb00c2968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tiger():\n",
    "    \n",
    "    sentences = []\n",
    "\n",
    "    with open(tiger_dataset,'r', encoding='iso-8859-15') as f:\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            while not '<terminals>' in line:\n",
    "                line = f.readline()\n",
    "                if '</corpus>' in line:\n",
    "                    return sentences\n",
    "            words = []\n",
    "            while not '</terminals>' in line:\n",
    "                line = f.readline()\n",
    "                s = re.search(r'word=\"(\\w+)\" lemma=\"(\\w+)\" pos=\"(\\w+)\"',line)\n",
    "                if s:\n",
    "                    words.append(s.groups(0))\n",
    "            if len(words)>0:\n",
    "                sentences.append(words)\n",
    "\n",
    "tiger_sentences = read_tiger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ed49b98-523b-4d52-87f5-4e9dbc8cfc9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49827"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tiger_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9e278e32-72ba-476a-a0f4-76f48afb4ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999\n"
     ]
    }
   ],
   "source": [
    "tiger_res = []\n",
    "\n",
    "for idx,sentence in enumerate(tiger_sentences):\n",
    "    words, lemmas, pos = zip(*sentence)\n",
    "    text = ' '.join(words)\n",
    "    doc = spacy_model(text)\n",
    "    if len(doc)==len(lemmas):\n",
    "        for token, tiger_word, tiger_lemma, tiger_pos in zip(doc,words,lemmas,pos):\n",
    "             if tiger_word == token.text and token.pos_ in ('NOUN','ADJ','ADV','VERB'):\n",
    "                   lemma = lemmatizer(spacy_token=token)\n",
    "                   tiger_res.append((text,tiger_word, tiger_pos, tiger_lemma, token.pos_, token.lemma_, lemma))\n",
    "    if (idx+1)%2000==0:\n",
    "        print(idx)\n",
    "        break\n",
    "\n",
    "tiger_res = pd.DataFrame(tiger_res, columns = ['sentence','word','tiger_pos','tiger_lemma','spacy_pos','spacy_lemma','pred_lemma'])\n",
    "\n",
    "tiger_res['correct'] = tiger_res.pred_lemma == tiger_res.tiger_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f59f86e5-a844-4555-b3a3-91886d3c80b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiger_res = tiger_res[~tiger_res.tiger_lemma.str.endswith('ß')]\n",
    "#tiger_res = tiger_res[~tiger_res.tiger_lemma.apply(lambda x:x.lower()==x)]\n",
    "#tiger_res = tiger_res[~tiger_res.tiger_lemma.apply(lambda x:x.upper()==x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8fa67c54-d4ca-4881-87d2-4248287f21e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy_pos\n",
       "ADJ     0.877870\n",
       "ADV     0.933382\n",
       "NOUN    0.941193\n",
       "VERB    0.993190\n",
       "Name: correct, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiger_res.groupby('spacy_pos').correct.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4bcf88cb-1433-4e73-b200-b9625f704bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word</th>\n",
       "      <th>tiger_lemma</th>\n",
       "      <th>pred_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Und ein anderer Manager vermutet daß sich ein Dogmatiker wie Perot in Washington schwer tun würde es sei denn er schafft den Kongreß ab</td>\n",
       "      <td>anderer</td>\n",
       "      <td>anderer</td>\n",
       "      <td>ander</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Allerdings gibt es dem Magazin zufolge in kleinen und mittleren Firmen viele Unternehmer die meinen Perot sei einer von ihnen und die den Texaner unterstützen</td>\n",
       "      <td>mittleren</td>\n",
       "      <td>mittlerer</td>\n",
       "      <td>mittel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Ihm gelingt es aber nicht den Koloß der der Regierung in Washington mehr ähnelt als jeder andere Konzern in Schwung zu bringen</td>\n",
       "      <td>andere</td>\n",
       "      <td>anderer</td>\n",
       "      <td>ander</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>Auch wenn Manmohan Singh immer wieder versichert er rechne nach der Öffnung der indischen Wirtschaft mit ausländischen Investitionen von bis zu sechs Milliarden Dollar im Laufe der nächsten drei Jahre so sind bis Ende März nicht mehr als 480 Millionen ins Land geflossen</td>\n",
       "      <td>nächsten</td>\n",
       "      <td>nächster</td>\n",
       "      <td>nahe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>Der zweite Punkt ist die Kürzung der Subventionen die mehr als ein Zehntel der Staatsausgaben verschlingen und von denen nicht etwa die Ärmsten der Armen profitieren</td>\n",
       "      <td>zweite</td>\n",
       "      <td>zweiter</td>\n",
       "      <td>zweite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>Nahrungsmittelsicherheit aber ist die erste Voraussetzung für Fortschritt und Stabilität in Indien</td>\n",
       "      <td>erste</td>\n",
       "      <td>erster</td>\n",
       "      <td>erste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>In den 60er Jahren hat man versucht die NPD auszugrenzen zu stigmatisieren mit guten Gründen</td>\n",
       "      <td>60er</td>\n",
       "      <td>60er</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>Nur Sie müssen bedenken daß die heutigen Abgeordneten der Rechtsaußenparteien biographisch weit entfernt sind vom Dritten Reich insofern entfällt die direkte symbolische Legitimation sie auszugrenzen</td>\n",
       "      <td>Dritten</td>\n",
       "      <td>dritter</td>\n",
       "      <td>dritte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>Und sie müssen bedenken daß heute die zugrundeliegenden Probleme das was diese Parteien eigentlich artikulieren sehr viel tiefer reichen als in den 50er und 60er Jahren</td>\n",
       "      <td>50er</td>\n",
       "      <td>50er</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>Genau dies verbindet sie übrigens mit den Vorläufern des Nationalsozialismus mit der Weimarer Rechten</td>\n",
       "      <td>Weimarer</td>\n",
       "      <td>Weimarer</td>\n",
       "      <td>weimarer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>FR Eine Auseinandersetzung ist ja immer auch ein Eingehen auf die Figuren die hochgespült werden auf der rechten Seite</td>\n",
       "      <td>rechten</td>\n",
       "      <td>rechter</td>\n",
       "      <td>recht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>In den Fragen etwa der inneren Sicherheit oder der Ausländerpolitik sind die Positionen der Republikaner der NPD und der CDU nicht sehr weit auseinander</td>\n",
       "      <td>inneren</td>\n",
       "      <td>innerer</td>\n",
       "      <td>inner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>Wo Leute mit Hakenkreuzen rummalen rumhantieren sind auch Journalisten sehr schnell da und bereit darüber zu berichten</td>\n",
       "      <td>rummalen</td>\n",
       "      <td>rummalen</td>\n",
       "      <td>rummal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>FR Uns steht eine relativ lange Zeit ohne Wahlen und Wahlkämpfe bevor</td>\n",
       "      <td>lange</td>\n",
       "      <td>lang</td>\n",
       "      <td>lange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>Jaschke ist wissenschaftlicher Mitarbeiter am Frankfurter Institut für Sozialforschung und Privatdozent für Politikwissenschaft an der Universität Frankfurt</td>\n",
       "      <td>Frankfurter</td>\n",
       "      <td>Frankfurter</td>\n",
       "      <td>frankfurter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>Viele Göttinger Autonome laufen zur Zeit mit einem unguten Gefühl durch die Stadt</td>\n",
       "      <td>Göttinger</td>\n",
       "      <td>Göttinger</td>\n",
       "      <td>göttinger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>Seit Ende letzten Jahres kommen täglich eine Handvoll Ermittler des niedersächsischen Landeskriminalamtes LKA aus Hannover nach Göttingen um die autonome Szene wegen des Verdachts der Gründung Mitgliedschaft oder Unterstützung einer terroristischen Vereinigung nach Paragraph 129 Strafgesetzbuch auszuforschen</td>\n",
       "      <td>letzten</td>\n",
       "      <td>letzter</td>\n",
       "      <td>letzte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>Anlaß für die Aktivitäten im Auftrag der Bundesanwaltschaft sind rund 50 unaufgeklärte und Brandanschläge in den vergangenen zehn Jahren zu denen sich diverse autonome Kommandos bekannt hatten</td>\n",
       "      <td>diverse</td>\n",
       "      <td>diverser</td>\n",
       "      <td>divers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>Eine der Gruppen die die Fahnder ins Visier genommen haben ist die sogenannte Autonome Antifa M</td>\n",
       "      <td>sogenannte</td>\n",
       "      <td>sogenannter</td>\n",
       "      <td>sogenannt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646</th>\n",
       "      <td>Da die Gruppe in einem Flugblatt wörtlich erklärte es sei ihr wichtiger denn je gezielt gegen das System und seine Büttel vorzugehen und auch den auf das Holzhaus des früheren Führers der ultrarechten FAP Karl Polacek im vergangenen Jahr als gutes Beispiel revolutionärer Tat lobte halten die Ermittler den aufrecht</td>\n",
       "      <td>ultrarechten</td>\n",
       "      <td>ultrarechter</td>\n",
       "      <td>ultrarecht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>Um die guten Nachbarschaftsbeziehungen zwischen der Eidgenossenschaft und Österreich nicht abrupt abbrechen zu lassen wie der Schweizer Volkswirtschaftsminister Delamuraz im Parlament darlegte werden gegenwärtig in Bern und Wien auf höchster Ebene Mistdossiers bearbeitet</td>\n",
       "      <td>Schweizer</td>\n",
       "      <td>Schweizer</td>\n",
       "      <td>schweizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>Für Thomas Giger Kantonstierarzt in und direkt zuständig für die Mistproblematik jener rund vierzig Grenzbauern des Rheintals die ihre Kühe auf Vorarlberger Boden weiden lassen handelt es sich beim zwischenstaatlichen Nachbarschaftsproblem um ein Musterbeispiel für Auswüchse und Verirrungen der Bürokratie</td>\n",
       "      <td>Vorarlberger</td>\n",
       "      <td>Vorarlberger</td>\n",
       "      <td>vorarlberger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237</th>\n",
       "      <td>Seit dem Zweiten Weltkrieg hätten sie das Recht gehabt die Kuhställe zu Lasten der Nachbarn zu säubern und den Hofabfall uneingeschränkt auf den zugepachteten Grundstücken im benachbarten Vorarlberg auszubringen dies ohne kostenpflichtige Formalitäten grollen die Rheintaler Bauern in Richtung Wien</td>\n",
       "      <td>Zweiten</td>\n",
       "      <td>zweiter</td>\n",
       "      <td>zweite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2253</th>\n",
       "      <td>Seit dem Zweiten Weltkrieg hätten sie das Recht gehabt die Kuhställe zu Lasten der Nachbarn zu säubern und den Hofabfall uneingeschränkt auf den zugepachteten Grundstücken im benachbarten Vorarlberg auszubringen dies ohne kostenpflichtige Formalitäten grollen die Rheintaler Bauern in Richtung Wien</td>\n",
       "      <td>Rheintaler</td>\n",
       "      <td>Rheintaler</td>\n",
       "      <td>rheintal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2318</th>\n",
       "      <td>Auf der unteren Ebene des Kantons und des Bundeslandes Vorarlberg legen sich Landamtmann Karl Mätzler für schweizerische und Landeshauptmann Martin Purtscher für österreichische Interessen ins Zeug</td>\n",
       "      <td>unteren</td>\n",
       "      <td>unterer</td>\n",
       "      <td>unter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2428</th>\n",
       "      <td>Die Hamburgische Landesbank erwartet auf absehbare Zeit eine anhaltend hohe Nachfrage nach Büroflächen</td>\n",
       "      <td>hohe</td>\n",
       "      <td>hoch</td>\n",
       "      <td>hoh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>Beigelegt ist der Streit über die Architektur am Kehrwieder deren ersten Entwurf Oberbaudirektor Egbert Kossak ganz unhanseatisch teils als zum Kotzen teils als amerikanischen Planungsschiet abgelehnt hatte</td>\n",
       "      <td>ersten</td>\n",
       "      <td>erster</td>\n",
       "      <td>erste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614</th>\n",
       "      <td>Der Wohnungsbau mahnt Hans Fahning muß in den nächsten Jahren allerhöchste Priorität haben wenn die Stadt zu einer ausgewogenen und sozial verträglichen Entwicklung finden soll</td>\n",
       "      <td>allerhöchste</td>\n",
       "      <td>allerhöchster</td>\n",
       "      <td>allerhöchst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2825</th>\n",
       "      <td>Vor den Augen der Pasdaran wurden die Bilder von Khomeiny Khamenei und Rafsandschani wie die anderen Symbole der klerikalen Herrschaft von den Wänden heruntergerissen</td>\n",
       "      <td>anderen</td>\n",
       "      <td>anderer</td>\n",
       "      <td>ander</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>Den Unruhen in der heiligen Stadt wo Ali der achte schiitische Imam begraben ist fielen dreißig bis vierzig Menschen zum Opfer</td>\n",
       "      <td>achte</td>\n",
       "      <td>achter</td>\n",
       "      <td>achte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2925</th>\n",
       "      <td>Sie benutzte die Lumpen Asozialen Dealer Messerstecher Schmarotzer und Geier für die eigenen Ziele</td>\n",
       "      <td>Asozialen</td>\n",
       "      <td>asoziale</td>\n",
       "      <td>asozial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2927</th>\n",
       "      <td>Sie benutzte die Lumpen Asozialen Dealer Messerstecher Schmarotzer und Geier für die eigenen Ziele</td>\n",
       "      <td>Messerstecher</td>\n",
       "      <td>Messerstecher</td>\n",
       "      <td>messerstech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2942</th>\n",
       "      <td>Um diesen Auftrag schariagemäß zu erfüllen erklärte der oberste Richter der Republik Ayatollah Jazdi die vermeintlichen Rädelsführer zu den Verderbern auf Erden</td>\n",
       "      <td>oberste</td>\n",
       "      <td>oberer</td>\n",
       "      <td>ober-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3081</th>\n",
       "      <td>In seinem Pariser Exil hatte Khomeiny dem Volk auf Heller und Pfennig vorgerechnet was man alles mit Öldevisen für die Schwachgehaltenen tun könnte</td>\n",
       "      <td>Pariser</td>\n",
       "      <td>Pariser</td>\n",
       "      <td>pariser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3192</th>\n",
       "      <td>Die langen Gefängnisstrafen Auspeitschungen und Hinrichtungen der Verderber auf Erden konnten jedenfalls die Unruhen nicht eindämmen</td>\n",
       "      <td>langen</td>\n",
       "      <td>lang</td>\n",
       "      <td>lange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3225</th>\n",
       "      <td>Zuletzt kam es in Täbris der zweitgrößten iranischen Stadt und der Metropole des persischen Aserbeidschan zu Demonstrationen</td>\n",
       "      <td>zweitgrößten</td>\n",
       "      <td>zweitgrößter</td>\n",
       "      <td>zweitgrößte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>Der Bielefelder Wissenschaftler Wilhelm Heitmeyer über die Ursachen von Gewalt in der jungen Generation und die Defizite der Politik</td>\n",
       "      <td>Bielefelder</td>\n",
       "      <td>Bielefelder</td>\n",
       "      <td>bielefeld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3299</th>\n",
       "      <td>Aus aktuellem Anlaß sprach mit ihm die Kölner Ingrid</td>\n",
       "      <td>Kölner</td>\n",
       "      <td>Kölner</td>\n",
       "      <td>kölner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3304</th>\n",
       "      <td>FR Was treibt Jugendliche dazu sich gewalttätigen sogenannten Härtegruppen anzuschließen und im Kreise Gleichgesinnter loszuschlagen</td>\n",
       "      <td>sogenannten</td>\n",
       "      <td>sogenannter</td>\n",
       "      <td>sogenannt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3566</th>\n",
       "      <td>Heitmeyer Wir müssen unterscheiden zwischen eher offenen physischen Gewaltformen die sich über männlich dominierte Gruppen in der Öffentlichkeit zeigen und solchen eher psychischen Gewaltformen die als Einzelaktivität eher mit einem hohen Bildungsgrad verbunden sind</td>\n",
       "      <td>hohen</td>\n",
       "      <td>hoch</td>\n",
       "      <td>hoh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3944</th>\n",
       "      <td>Castellanos war bislang vielmehr ein Getreuer der an die Revolution glaubte sich freiwillig für den meldete ein ein unpolitischer Akademiker der sich mit dem wenigen beschied wissend daß sein Beruf in anderen Ländern ein Vielfaches einbringt</td>\n",
       "      <td>wenigen</td>\n",
       "      <td>weniger</td>\n",
       "      <td>wenig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4502</th>\n",
       "      <td>Der Bonner Helmut Lölhöffel stellt die drei Gremien vor</td>\n",
       "      <td>Bonner</td>\n",
       "      <td>Bonner</td>\n",
       "      <td>bonner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4626</th>\n",
       "      <td>In einem Zwischenbericht vom Mai 1991 hatte die Kommission festgehalten daß die Vermögen der betroffenen Institutionen teilweise von ganz erheblichem Umfang und großer Vielfalt sowohl an Grundbesitz als auch an Betriebsvermögen und an liquiden Mitteln sind</td>\n",
       "      <td>liquiden</td>\n",
       "      <td>liquid</td>\n",
       "      <td>liquide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4912</th>\n",
       "      <td>Eine Million Bauern gab seit den fünfziger Jahren auf</td>\n",
       "      <td>fünfziger</td>\n",
       "      <td>fünfziger</td>\n",
       "      <td>fünfzig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5136</th>\n",
       "      <td>Oft ist nicht einmal mehr genug Geld da um die Saat für die nächste Ernte einkaufen zu können Gebäude verkommen Flächen liegen brach</td>\n",
       "      <td>nächste</td>\n",
       "      <td>nächster</td>\n",
       "      <td>nahe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5240</th>\n",
       "      <td>Vor allem die Berliner Treuhandanstalt soll daher mit einer klugen Privatisierungspolitik einen Zerfall verhindern</td>\n",
       "      <td>Berliner</td>\n",
       "      <td>Berliner</td>\n",
       "      <td>berliner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5262</th>\n",
       "      <td>Eigentumsverhältnisse müssen bis in die dreißiger Jahre zurück aufgedröselt werden</td>\n",
       "      <td>dreißiger</td>\n",
       "      <td>dreißiger</td>\n",
       "      <td>dreißig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5315</th>\n",
       "      <td>Ein Verkauf kam kaum in Frage zumal viele Ostbauern sich den Grundstückserwerb ohnehin nicht leisten könnten Fördermodelle wegen des Streits über den Kreis der Begünstigten auf Eis liegen und so nur die westdeutsche Konkurrenz zum Zuge käme</td>\n",
       "      <td>Begünstigten</td>\n",
       "      <td>begünstigter</td>\n",
       "      <td>begünstigt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5348</th>\n",
       "      <td>Vor kurzem hat die Treuhand deshalb nach langem Hin und Her die zwölfjährige Pacht eingeführt und dafür die und BVVG gegründet an der neben der Anstalt drei Agrarfinanziers Landwirtschaftliche Rentenbank Landeskreditbank je ein Viertel des Kapitals halten</td>\n",
       "      <td>langem</td>\n",
       "      <td>lang</td>\n",
       "      <td>lange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5434</th>\n",
       "      <td>Es wird noch lange dauern bis der letzte Vermögensstreit ausgefochten ist und jeder Bauer seine Scholle in Ruhe bewirtschaften kann</td>\n",
       "      <td>letzte</td>\n",
       "      <td>letzter</td>\n",
       "      <td>letzte</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                         sentence  \\\n",
       "112                                                                                                                                                                                       Und ein anderer Manager vermutet daß sich ein Dogmatiker wie Perot in Washington schwer tun würde es sei denn er schafft den Kongreß ab   \n",
       "136                                                                                                                                                                Allerdings gibt es dem Magazin zufolge in kleinen und mittleren Firmen viele Unternehmer die meinen Perot sei einer von ihnen und die den Texaner unterstützen   \n",
       "204                                                                                                                                                                                                Ihm gelingt es aber nicht den Koloß der der Regierung in Washington mehr ähnelt als jeder andere Konzern in Schwung zu bringen   \n",
       "591                                                Auch wenn Manmohan Singh immer wieder versichert er rechne nach der Öffnung der indischen Wirtschaft mit ausländischen Investitionen von bis zu sechs Milliarden Dollar im Laufe der nächsten drei Jahre so sind bis Ende März nicht mehr als 480 Millionen ins Land geflossen   \n",
       "692                                                                                                                                                         Der zweite Punkt ist die Kürzung der Subventionen die mehr als ein Zehntel der Staatsausgaben verschlingen und von denen nicht etwa die Ärmsten der Armen profitieren   \n",
       "716                                                                                                                                                                                                                            Nahrungsmittelsicherheit aber ist die erste Voraussetzung für Fortschritt und Stabilität in Indien   \n",
       "784                                                                                                                                                                                                                                  In den 60er Jahren hat man versucht die NPD auszugrenzen zu stigmatisieren mit guten Gründen   \n",
       "826                                                                                                                       Nur Sie müssen bedenken daß die heutigen Abgeordneten der Rechtsaußenparteien biographisch weit entfernt sind vom Dritten Reich insofern entfällt die direkte symbolische Legitimation sie auszugrenzen   \n",
       "845                                                                                                                                                      Und sie müssen bedenken daß heute die zugrundeliegenden Probleme das was diese Parteien eigentlich artikulieren sehr viel tiefer reichen als in den 50er und 60er Jahren   \n",
       "920                                                                                                                                                                                                                         Genau dies verbindet sie übrigens mit den Vorläufern des Nationalsozialismus mit der Weimarer Rechten   \n",
       "950                                                                                                                                                                                                        FR Eine Auseinandersetzung ist ja immer auch ein Eingehen auf die Figuren die hochgespült werden auf der rechten Seite   \n",
       "1141                                                                                                                                                                     In den Fragen etwa der inneren Sicherheit oder der Ausländerpolitik sind die Positionen der Republikaner der NPD und der CDU nicht sehr weit auseinander   \n",
       "1167                                                                                                                                                                                                       Wo Leute mit Hakenkreuzen rummalen rumhantieren sind auch Journalisten sehr schnell da und bereit darüber zu berichten   \n",
       "1263                                                                                                                                                                                                                                                        FR Uns steht eine relativ lange Zeit ohne Wahlen und Wahlkämpfe bevor   \n",
       "1429                                                                                                                                                                 Jaschke ist wissenschaftlicher Mitarbeiter am Frankfurter Institut für Sozialforschung und Privatdozent für Politikwissenschaft an der Universität Frankfurt   \n",
       "1442                                                                                                                                                                                                                                            Viele Göttinger Autonome laufen zur Zeit mit einem unguten Gefühl durch die Stadt   \n",
       "1450        Seit Ende letzten Jahres kommen täglich eine Handvoll Ermittler des niedersächsischen Landeskriminalamtes LKA aus Hannover nach Göttingen um die autonome Szene wegen des Verdachts der Gründung Mitgliedschaft oder Unterstützung einer terroristischen Vereinigung nach Paragraph 129 Strafgesetzbuch auszuforschen   \n",
       "1477                                                                                                                             Anlaß für die Aktivitäten im Auftrag der Bundesanwaltschaft sind rund 50 unaufgeklärte und Brandanschläge in den vergangenen zehn Jahren zu denen sich diverse autonome Kommandos bekannt hatten   \n",
       "1521                                                                                                                                                                                                                              Eine der Gruppen die die Fahnder ins Visier genommen haben ist die sogenannte Autonome Antifa M   \n",
       "1646  Da die Gruppe in einem Flugblatt wörtlich erklärte es sei ihr wichtiger denn je gezielt gegen das System und seine Büttel vorzugehen und auch den auf das Holzhaus des früheren Führers der ultrarechten FAP Karl Polacek im vergangenen Jahr als gutes Beispiel revolutionärer Tat lobte halten die Ermittler den aufrecht   \n",
       "2145                                              Um die guten Nachbarschaftsbeziehungen zwischen der Eidgenossenschaft und Österreich nicht abrupt abbrechen zu lassen wie der Schweizer Volkswirtschaftsminister Delamuraz im Parlament darlegte werden gegenwärtig in Bern und Wien auf höchster Ebene Mistdossiers bearbeitet   \n",
       "2199           Für Thomas Giger Kantonstierarzt in und direkt zuständig für die Mistproblematik jener rund vierzig Grenzbauern des Rheintals die ihre Kühe auf Vorarlberger Boden weiden lassen handelt es sich beim zwischenstaatlichen Nachbarschaftsproblem um ein Musterbeispiel für Auswüchse und Verirrungen der Bürokratie   \n",
       "2237                   Seit dem Zweiten Weltkrieg hätten sie das Recht gehabt die Kuhställe zu Lasten der Nachbarn zu säubern und den Hofabfall uneingeschränkt auf den zugepachteten Grundstücken im benachbarten Vorarlberg auszubringen dies ohne kostenpflichtige Formalitäten grollen die Rheintaler Bauern in Richtung Wien   \n",
       "2253                   Seit dem Zweiten Weltkrieg hätten sie das Recht gehabt die Kuhställe zu Lasten der Nachbarn zu säubern und den Hofabfall uneingeschränkt auf den zugepachteten Grundstücken im benachbarten Vorarlberg auszubringen dies ohne kostenpflichtige Formalitäten grollen die Rheintaler Bauern in Richtung Wien   \n",
       "2318                                                                                                                        Auf der unteren Ebene des Kantons und des Bundeslandes Vorarlberg legen sich Landamtmann Karl Mätzler für schweizerische und Landeshauptmann Martin Purtscher für österreichische Interessen ins Zeug   \n",
       "2428                                                                                                                                                                                                                       Die Hamburgische Landesbank erwartet auf absehbare Zeit eine anhaltend hohe Nachfrage nach Büroflächen   \n",
       "2493                                                                                                               Beigelegt ist der Streit über die Architektur am Kehrwieder deren ersten Entwurf Oberbaudirektor Egbert Kossak ganz unhanseatisch teils als zum Kotzen teils als amerikanischen Planungsschiet abgelehnt hatte   \n",
       "2614                                                                                                                                             Der Wohnungsbau mahnt Hans Fahning muß in den nächsten Jahren allerhöchste Priorität haben wenn die Stadt zu einer ausgewogenen und sozial verträglichen Entwicklung finden soll   \n",
       "2825                                                                                                                                                       Vor den Augen der Pasdaran wurden die Bilder von Khomeiny Khamenei und Rafsandschani wie die anderen Symbole der klerikalen Herrschaft von den Wänden heruntergerissen   \n",
       "2910                                                                                                                                                                                               Den Unruhen in der heiligen Stadt wo Ali der achte schiitische Imam begraben ist fielen dreißig bis vierzig Menschen zum Opfer   \n",
       "2925                                                                                                                                                                                                                           Sie benutzte die Lumpen Asozialen Dealer Messerstecher Schmarotzer und Geier für die eigenen Ziele   \n",
       "2927                                                                                                                                                                                                                           Sie benutzte die Lumpen Asozialen Dealer Messerstecher Schmarotzer und Geier für die eigenen Ziele   \n",
       "2942                                                                                                                                                             Um diesen Auftrag schariagemäß zu erfüllen erklärte der oberste Richter der Republik Ayatollah Jazdi die vermeintlichen Rädelsführer zu den Verderbern auf Erden   \n",
       "3081                                                                                                                                                                          In seinem Pariser Exil hatte Khomeiny dem Volk auf Heller und Pfennig vorgerechnet was man alles mit Öldevisen für die Schwachgehaltenen tun könnte   \n",
       "3192                                                                                                                                                                                         Die langen Gefängnisstrafen Auspeitschungen und Hinrichtungen der Verderber auf Erden konnten jedenfalls die Unruhen nicht eindämmen   \n",
       "3225                                                                                                                                                                                                 Zuletzt kam es in Täbris der zweitgrößten iranischen Stadt und der Metropole des persischen Aserbeidschan zu Demonstrationen   \n",
       "3264                                                                                                                                                                                         Der Bielefelder Wissenschaftler Wilhelm Heitmeyer über die Ursachen von Gewalt in der jungen Generation und die Defizite der Politik   \n",
       "3299                                                                                                                                                                                                                                                                         Aus aktuellem Anlaß sprach mit ihm die Kölner Ingrid   \n",
       "3304                                                                                                                                                                                         FR Was treibt Jugendliche dazu sich gewalttätigen sogenannten Härtegruppen anzuschließen und im Kreise Gleichgesinnter loszuschlagen   \n",
       "3566                                                   Heitmeyer Wir müssen unterscheiden zwischen eher offenen physischen Gewaltformen die sich über männlich dominierte Gruppen in der Öffentlichkeit zeigen und solchen eher psychischen Gewaltformen die als Einzelaktivität eher mit einem hohen Bildungsgrad verbunden sind   \n",
       "3944                                                                            Castellanos war bislang vielmehr ein Getreuer der an die Revolution glaubte sich freiwillig für den meldete ein ein unpolitischer Akademiker der sich mit dem wenigen beschied wissend daß sein Beruf in anderen Ländern ein Vielfaches einbringt   \n",
       "4502                                                                                                                                                                                                                                                                      Der Bonner Helmut Lölhöffel stellt die drei Gremien vor   \n",
       "4626                                                             In einem Zwischenbericht vom Mai 1991 hatte die Kommission festgehalten daß die Vermögen der betroffenen Institutionen teilweise von ganz erheblichem Umfang und großer Vielfalt sowohl an Grundbesitz als auch an Betriebsvermögen und an liquiden Mitteln sind   \n",
       "4912                                                                                                                                                                                                                                                                        Eine Million Bauern gab seit den fünfziger Jahren auf   \n",
       "5136                                                                                                                                                                                         Oft ist nicht einmal mehr genug Geld da um die Saat für die nächste Ernte einkaufen zu können Gebäude verkommen Flächen liegen brach   \n",
       "5240                                                                                                                                                                                                           Vor allem die Berliner Treuhandanstalt soll daher mit einer klugen Privatisierungspolitik einen Zerfall verhindern   \n",
       "5262                                                                                                                                                                                                                                           Eigentumsverhältnisse müssen bis in die dreißiger Jahre zurück aufgedröselt werden   \n",
       "5315                                                                             Ein Verkauf kam kaum in Frage zumal viele Ostbauern sich den Grundstückserwerb ohnehin nicht leisten könnten Fördermodelle wegen des Streits über den Kreis der Begünstigten auf Eis liegen und so nur die westdeutsche Konkurrenz zum Zuge käme   \n",
       "5348                                                              Vor kurzem hat die Treuhand deshalb nach langem Hin und Her die zwölfjährige Pacht eingeführt und dafür die und BVVG gegründet an der neben der Anstalt drei Agrarfinanziers Landwirtschaftliche Rentenbank Landeskreditbank je ein Viertel des Kapitals halten   \n",
       "5434                                                                                                                                                                                          Es wird noch lange dauern bis der letzte Vermögensstreit ausgefochten ist und jeder Bauer seine Scholle in Ruhe bewirtschaften kann   \n",
       "\n",
       "               word    tiger_lemma    pred_lemma  \n",
       "112         anderer        anderer         ander  \n",
       "136       mittleren      mittlerer        mittel  \n",
       "204          andere        anderer         ander  \n",
       "591        nächsten       nächster          nahe  \n",
       "692          zweite        zweiter        zweite  \n",
       "716           erste         erster         erste  \n",
       "784            60er           60er            60  \n",
       "826         Dritten        dritter        dritte  \n",
       "845            50er           50er            50  \n",
       "920        Weimarer       Weimarer      weimarer  \n",
       "950         rechten        rechter         recht  \n",
       "1141        inneren        innerer         inner  \n",
       "1167       rummalen       rummalen        rummal  \n",
       "1263          lange           lang         lange  \n",
       "1429    Frankfurter    Frankfurter   frankfurter  \n",
       "1442      Göttinger      Göttinger     göttinger  \n",
       "1450        letzten        letzter        letzte  \n",
       "1477        diverse       diverser        divers  \n",
       "1521     sogenannte    sogenannter     sogenannt  \n",
       "1646   ultrarechten   ultrarechter    ultrarecht  \n",
       "2145      Schweizer      Schweizer     schweizer  \n",
       "2199   Vorarlberger   Vorarlberger  vorarlberger  \n",
       "2237        Zweiten        zweiter        zweite  \n",
       "2253     Rheintaler     Rheintaler      rheintal  \n",
       "2318        unteren        unterer         unter  \n",
       "2428           hohe           hoch           hoh  \n",
       "2493         ersten         erster         erste  \n",
       "2614   allerhöchste  allerhöchster   allerhöchst  \n",
       "2825        anderen        anderer         ander  \n",
       "2910          achte         achter         achte  \n",
       "2925      Asozialen       asoziale       asozial  \n",
       "2927  Messerstecher  Messerstecher   messerstech  \n",
       "2942        oberste         oberer         ober-  \n",
       "3081        Pariser        Pariser       pariser  \n",
       "3192         langen           lang         lange  \n",
       "3225   zweitgrößten   zweitgrößter   zweitgrößte  \n",
       "3264    Bielefelder    Bielefelder     bielefeld  \n",
       "3299         Kölner         Kölner        kölner  \n",
       "3304    sogenannten    sogenannter     sogenannt  \n",
       "3566          hohen           hoch           hoh  \n",
       "3944        wenigen        weniger         wenig  \n",
       "4502         Bonner         Bonner        bonner  \n",
       "4626       liquiden         liquid       liquide  \n",
       "4912      fünfziger      fünfziger       fünfzig  \n",
       "5136        nächste       nächster          nahe  \n",
       "5240       Berliner       Berliner      berliner  \n",
       "5262      dreißiger      dreißiger       dreißig  \n",
       "5315   Begünstigten   begünstigter    begünstigt  \n",
       "5348         langem           lang         lange  \n",
       "5434         letzte        letzter        letzte  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fails_df = tiger_res[(tiger_res.tiger_lemma!=tiger_res.pred_lemma)&(tiger_res.tiger_lemma==tiger_res.spacy_lemma)].drop_duplicates(subset=['word','tiger_lemma'])\n",
    "fails_df[fails_df.spacy_pos=='ADJ'].loc[~fails_df.pred_lemma.isna(),['sentence','word','tiger_lemma','pred_lemma']].head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af64ab0a-edb0-4595-8fc0-4b9d076272c2",
   "metadata": {},
   "source": [
    "## Test HDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df8c2f5b-2c6f-434e-bc1b-059593b4ca05",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdt_dataset = 'data/third-party/UD_German-HDT/de_hdt-ud-train-a-1.conllu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d07aa9f6-a6aa-48d9-9b49-9e2f13e520ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hdt():\n",
    "    \n",
    "    sentences = []\n",
    "    words = []\n",
    "\n",
    "    prev_sent_id = ''\n",
    "    \n",
    "    with open(hdt_dataset,'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if 'sent_id' in line:\n",
    "                sent_id = re.search(r'sent_id = (.+)',line).groups(1)\n",
    "                if sent_id!=prev_sent_id:\n",
    "                    if words:\n",
    "                        sentences.append(words)\n",
    "                    words = []\n",
    "                    prev_sent_id = sent_id\n",
    "            else:\n",
    "                s = re.match(r'[0-9]+\\t([\\w]+)\\t([\\w]+)\\t([\\w]+)',line)\n",
    "                if s:\n",
    "                    words.append(s.groups(0))\n",
    "\n",
    "    return sentences\n",
    "\n",
    "sentences_hdt = read_hdt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "babac098-4bb7-403b-a6b3-411f9f712cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999\n"
     ]
    }
   ],
   "source": [
    "hdt_res = []\n",
    "\n",
    "for idx,sentence in enumerate(sentences_hdt):\n",
    "    words, lemmas, pos = zip(*sentence)\n",
    "    text = ' '.join(words)\n",
    "    doc = spacy_model(text)\n",
    "    if len(doc)==len(lemmas):\n",
    "        for token, hdt_word, hdt_lemma, hdt_pos in zip(doc,words,lemmas,pos):\n",
    "             if hdt_word == token.text and token.pos_ in ('NOUN','ADJ','ADV','VERB'):\n",
    "                   lemma = lemmatizer(spacy_token=token)\n",
    "                   hdt_res.append((text,hdt_word, hdt_pos, hdt_lemma, token.pos_, token.lemma_, lemma))\n",
    "    if (idx+1)%2000==0:\n",
    "        print(idx)\n",
    "        break\n",
    "\n",
    "hdt_res = pd.DataFrame(hdt_res, columns = ['sentence','word','hdt_pos','hdt_lemma','spacy_pos','spacy_lemma','pred_lemma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b226d0fd-30de-4a7b-91e6-03616da25030",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdt_res = hdt_res[~hdt_res.hdt_lemma.str.endswith('ß')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cccdca1b-d687-4c4d-b470-874b4c5eb76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy_pos\n",
       "ADJ     0.859504\n",
       "ADV     0.939639\n",
       "NOUN    0.941193\n",
       "VERB    0.993190\n",
       "Name: correct, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiger_res.groupby('spacy_pos').correct.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b609a38-1f34-4577-93a1-dfff7111be72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word</th>\n",
       "      <th>hdt_lemma</th>\n",
       "      <th>pred_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Zudem würden bei der Portierung einer Rufnummer von einem Anbieter zu dem anderen einige Leistungsmerkmale womöglich nicht mehr zu der Verfügung stehen etwa bestimmte Mailboxdienste</td>\n",
       "      <td>anderen</td>\n",
       "      <td>anderer</td>\n",
       "      <td>ander</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Zudem würden bei der Portierung einer Rufnummer von einem Anbieter zu dem anderen einige Leistungsmerkmale womöglich nicht mehr zu der Verfügung stehen etwa bestimmte Mailboxdienste</td>\n",
       "      <td>mehr</td>\n",
       "      <td>mehr</td>\n",
       "      <td>viel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Die Betreiber von Mobilfunknetzen müssen der RegTP vierteljährlich über den Verlauf der Realisierungsarbeiten berichten</td>\n",
       "      <td>RegTP</td>\n",
       "      <td>RegTP</td>\n",
       "      <td>Regtp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>Das Unternehmen musste jetzt bei dem Potsdamer Amtsgericht Insolvenz anmelden</td>\n",
       "      <td>Potsdamer</td>\n",
       "      <td>Potsdamer</td>\n",
       "      <td>potsdamer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>Über die Gründe der Insolvenz konnte Unternehmenssprecher Johannes noch nichts sagen kündigte jedoch die Bekanntgabe weiterer Details für die Mitte dieser Woche an</td>\n",
       "      <td>weiterer</td>\n",
       "      <td>weit</td>\n",
       "      <td>weiter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>Die RegTP erteilte die Genehmigung weil ihr die bisher vorliegenden Daten nicht ausreichend erschienen um das abschließend beurteilen zu können</td>\n",
       "      <td>Daten</td>\n",
       "      <td>Datum</td>\n",
       "      <td>Daten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>Nutzer des können für Mark monatlich einschließlich und für normale Werktage an und Feiertagen kostenlos in dem gesamten deutschen telefonieren</td>\n",
       "      <td>können</td>\n",
       "      <td>können</td>\n",
       "      <td>Können</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>Seit dem heutigen Mittwochmorgen kursierten an der Frankfurter Börse Gerüchte denen zufolge Ron Sommer zurücktreten wird</td>\n",
       "      <td>Frankfurter</td>\n",
       "      <td>Frankfurter</td>\n",
       "      <td>frankfurter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>Letztlich dürfte es sich bei dem Gerücht lediglich um eine Begleiterscheinung der Talfahrt des Kurses der handeln</td>\n",
       "      <td>handeln</td>\n",
       "      <td>handeln</td>\n",
       "      <td>Handeln</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>Der Nemax50 verlor seit heute Morgen knapp fünf Prozent</td>\n",
       "      <td>Morgen</td>\n",
       "      <td>Morgen</td>\n",
       "      <td>morgen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>Der Kölner Stadtnetzbetreiber NetCologne will mit Mannesmann Arcor einen Vertrag über den Zugang zu der Teilnehmeranschlussleitung der so genannten letzten Meile abschließen</td>\n",
       "      <td>Kölner</td>\n",
       "      <td>Kölner</td>\n",
       "      <td>kölner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>Weitere Details sollen erst an dem morgigen Donnerstag bekannt gegeben werden</td>\n",
       "      <td>Weitere</td>\n",
       "      <td>weit</td>\n",
       "      <td>weiter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>Entsprechende Spekulationen gab es bereits seit längerem</td>\n",
       "      <td>längerem</td>\n",
       "      <td>lang</td>\n",
       "      <td>lange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>Die Bundesregierung spricht sich desweiteren dafür aus dass die Abgaben bei wegen der mehrfachen Überschreibbarkeit der Medien höher ausfallen sollten als bei da hier nur eine einmalige Vervielfältigungsmöglichkeit gegeben sei</td>\n",
       "      <td>Medien</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>Der Vergütungsbericht der Bundesregierung wird in Abständen in dem Auftrag des Bundestages erstellt um über die Entwicklung und Angemessenheit von Vergütungen nach 54 Urheberrechtsgesetz UrhG und insbesondere der Anlage zu 54 d 1 UrhG zu berichten</td>\n",
       "      <td>UrhG</td>\n",
       "      <td>UrhG</td>\n",
       "      <td>Urhg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>Geplant ist gleich eine ganze Serie von Spielen zu veröffentlichen die sich nach Aussage von Don Mattrick President der EA worldwide studios eng an den Romanvorlagen und an dem demnächst erscheinenden Harry orientieren</td>\n",
       "      <td>Spielen</td>\n",
       "      <td>Spiel</td>\n",
       "      <td>Spielen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>Grund für die Sperrung ist nach offiziellen Angaben dass auf diesen Seiten pornografisches Material und anderes Anstößiges zu finden sei</td>\n",
       "      <td>anderes</td>\n",
       "      <td>anderer</td>\n",
       "      <td>ander</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>Yahoo hat durch die Maßnahme jetzt in einem weiteren Land mit Problemen zu kämpfen</td>\n",
       "      <td>weiteren</td>\n",
       "      <td>weit</td>\n",
       "      <td>weiter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>Der Kopierschutz besteht nach Angaben von Intel aus einem das die sichere Verwaltung von Musik auf dem PC und deren Übertragung auf tragbare Audiogeräte und Speichermedien ermöglichen soll</td>\n",
       "      <td>PC</td>\n",
       "      <td>PC</td>\n",
       "      <td>Pc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>Intels Softwarepaket soll die entscheidenden Codes Schlüssel und andere wichtige Informationen der vor dem Zugriff Dritter verbergen und Versuche erkennen den Sicherheitsmechanismus zu überwinden</td>\n",
       "      <td>andere</td>\n",
       "      <td>anderer</td>\n",
       "      <td>ander</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>Der Messenger kommt für Linux in dem und umfasst gerade einmal knapp über 100 KByte</td>\n",
       "      <td>KByte</td>\n",
       "      <td>KByte</td>\n",
       "      <td>Kbyte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>Die Bonner Staatsanwaltschaft nahm wegen des Verdachts auf Kapitalanlagebetrug Ermittlungen gegen mehrere Vorstände auf</td>\n",
       "      <td>Bonner</td>\n",
       "      <td>Bonner</td>\n",
       "      <td>bonner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>Nach dem März können sich für flat den Pauschaltarif für und nicht mehr neu anmelden</td>\n",
       "      <td>flat</td>\n",
       "      <td>flat</td>\n",
       "      <td>Flat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>Verbringt er in dem Monat weniger Stunden in dem Internet als er bezahlt hat so verfallen die restlichen Stunden surft er dagegen mehr kostet jede weitere Minute Pfennig</td>\n",
       "      <td>weitere</td>\n",
       "      <td>weit</td>\n",
       "      <td>weiter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>Tiefrot waren die Zahlen die die Ende Januar auf der Bilanzpressekonferenz zu verkünden hatte</td>\n",
       "      <td>Tiefrot</td>\n",
       "      <td>Tiefrot</td>\n",
       "      <td>tiefrot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>Nicht die sind nach seinen Worten die größten Barrieren für den neuer Zielgruppen sondern die unverändert hohen</td>\n",
       "      <td>hohen</td>\n",
       "      <td>hoch</td>\n",
       "      <td>hoh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>Callahan übernimmt 55 Prozent der Anteile von der Deutschen Telekom und will das Kabelnetz für interaktives Fernsehen und einen schnellen ausbauen</td>\n",
       "      <td>ausbauen</td>\n",
       "      <td>ausbauen</td>\n",
       "      <td>Ausbau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>Die die als 347 MByte großes gepacktes auf die Platte kommt enthält neben dem eigentlichen Linux noch den XMMS den Acrobat Reader den Macromedia Flash Player 4 einen Instant Messenger die eFax sowie den Netscape Communicator</td>\n",
       "      <td>MByte</td>\n",
       "      <td>MByte</td>\n",
       "      <td>Mbyte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>Die die als 347 MByte großes gepacktes auf die Platte kommt enthält neben dem eigentlichen Linux noch den XMMS den Acrobat Reader den Macromedia Flash Player 4 einen Instant Messenger die eFax sowie den Netscape Communicator</td>\n",
       "      <td>eFax</td>\n",
       "      <td>eFax</td>\n",
       "      <td>Efax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2285</th>\n",
       "      <td>Die die für knapp 25 auf CD bestellt werden kann bietet zusätzlich einen User Guide technischen Support per für 30 Tage sowie das Loki Entertainment Pack mit einigen</td>\n",
       "      <td>CD</td>\n",
       "      <td>CD</td>\n",
       "      <td>Cd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419</th>\n",
       "      <td>Insgesamt arbeiten momentan noch rund 250 Mitarbeiter in der Dortmunder Niederlassung</td>\n",
       "      <td>Dortmunder</td>\n",
       "      <td>Dortmunder</td>\n",
       "      <td>dortmunder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2421</th>\n",
       "      <td>Zukünftig will Versatel enger mit dem Tochterunternehmen KomTel in Flensburg zusammenarbeiten und nutzen</td>\n",
       "      <td>Zukünftig</td>\n",
       "      <td>Zukünftig</td>\n",
       "      <td>zukünftig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>Mit dem türkischsprachigen Angebot steht aber nicht alleine dar</td>\n",
       "      <td>alleine</td>\n",
       "      <td>alleine</td>\n",
       "      <td>allein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2722</th>\n",
       "      <td>Wenn da jetzt 5 Prozent Kunden anderer Provider hinzukämen würde das kaum etwas ausmachen</td>\n",
       "      <td>anderer</td>\n",
       "      <td>anderer</td>\n",
       "      <td>ander</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2738</th>\n",
       "      <td>Wenn es also tatsächlich zu Engpässen kommen würde dann sei die Telekom schuld und niemand anderes</td>\n",
       "      <td>schuld</td>\n",
       "      <td>schuld</td>\n",
       "      <td>Schuld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2780</th>\n",
       "      <td>Wenn der VATM jetzt argumentiere dass die Provider zu hohe Kosten aufzuwenden hätten um eine bundesweite Flatrate anbieten zu können dann sei das so nicht richtig</td>\n",
       "      <td>hohe</td>\n",
       "      <td>hoch</td>\n",
       "      <td>hoh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3263</th>\n",
       "      <td>Dass die Entscheidung des Gerichtes auch auf die Einstellung der zurückzuführen ist findet AOL bezeichnend</td>\n",
       "      <td>zurückzuführen</td>\n",
       "      <td>zurückführen</td>\n",
       "      <td>zurückzuführ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3838</th>\n",
       "      <td>Wie Ministeriumssprecher Michael Knaps gegenüber heise online sagte wollte die Mordkommission ein Forum auf einer Alfelder zu der Suche nach Hinweisen in einem Mordfall nutzen</td>\n",
       "      <td>Alfelder</td>\n",
       "      <td>Alfelder</td>\n",
       "      <td>alfeld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3921</th>\n",
       "      <td>Dass Streamgate zu seinem Vorteil den Unmut all jener ausnutzen wollte die derzeit immer noch zu Hunderttausenden auf den bestellten warten und sich zudem durch die penetrante Robert Werbung veralbert fühlen dürften wird der Telekom nicht gefallen haben</td>\n",
       "      <td>warten</td>\n",
       "      <td>warten</td>\n",
       "      <td>Warte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>Enthalten ist darin ein Transfervolumen von 500 MByte jedes weitere GByte kostet 69 Mark</td>\n",
       "      <td>GByte</td>\n",
       "      <td>GByte</td>\n",
       "      <td>Gbyte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4046</th>\n",
       "      <td>Es sollen keine festen vergeben werden bei Inaktivität wird die Verbindung getrennt</td>\n",
       "      <td>festen</td>\n",
       "      <td>fest</td>\n",
       "      <td>Feste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4149</th>\n",
       "      <td>Vorher waren bereits die Star Telecom und TelDaFax davon betroffen</td>\n",
       "      <td>betroffen</td>\n",
       "      <td>betreffen</td>\n",
       "      <td>betroffen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4347</th>\n",
       "      <td>Betroffen waren laut Clemens Gerth zirka Kunden die ihre über den Berliner Anbieter laufen lassen</td>\n",
       "      <td>Berliner</td>\n",
       "      <td>Berliner</td>\n",
       "      <td>berliner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4415</th>\n",
       "      <td>Ein soll das Auslesen von und die Umwandlung der Songs in das ermöglichen</td>\n",
       "      <td>ermöglichen</td>\n",
       "      <td>ermöglichen</td>\n",
       "      <td>Ermöglicher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4427</th>\n",
       "      <td>Wer damit eine auslesen und auf die Festplatte kopieren wollte war auf das WMA angewiesen</td>\n",
       "      <td>angewiesen</td>\n",
       "      <td>anweisen</td>\n",
       "      <td>angewiesen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4434</th>\n",
       "      <td>Ein weiteres soll das Abspielen von DVDs ermöglichen</td>\n",
       "      <td>weiteres</td>\n",
       "      <td>weit</td>\n",
       "      <td>weiter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4446</th>\n",
       "      <td>Das MP3 Creation Pack und das DVD Decoder Pack kann man unabhängig voneinander kaufen</td>\n",
       "      <td>MP3</td>\n",
       "      <td>MP3</td>\n",
       "      <td>mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4447</th>\n",
       "      <td>Das MP3 Creation Pack und das DVD Decoder Pack kann man unabhängig voneinander kaufen</td>\n",
       "      <td>DVD</td>\n",
       "      <td>DVD</td>\n",
       "      <td>Dvd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4468</th>\n",
       "      <td>Hierzu hatte das Unternehmen Anfang Mai die Voraussetzungen geschaffen und mit einen Vertrag über die Anmietung von geschlossen</td>\n",
       "      <td>geschlossen</td>\n",
       "      <td>schließen</td>\n",
       "      <td>geschlossen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4497</th>\n",
       "      <td>Schuld an der Verschiebung ist laut Kiyoyuki Tsujimura Managing Director von DoCoMo nicht das eigene Unternehmen Schuld seien die europäischen Netzanbieter</td>\n",
       "      <td>DoCoMo</td>\n",
       "      <td>DoCoMo</td>\n",
       "      <td>Docomo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                           sentence  \\\n",
       "156                                                                           Zudem würden bei der Portierung einer Rufnummer von einem Anbieter zu dem anderen einige Leistungsmerkmale womöglich nicht mehr zu der Verfügung stehen etwa bestimmte Mailboxdienste   \n",
       "159                                                                           Zudem würden bei der Portierung einer Rufnummer von einem Anbieter zu dem anderen einige Leistungsmerkmale womöglich nicht mehr zu der Verfügung stehen etwa bestimmte Mailboxdienste   \n",
       "195                                                                                                                                         Die Betreiber von Mobilfunknetzen müssen der RegTP vierteljährlich über den Verlauf der Realisierungsarbeiten berichten   \n",
       "263                                                                                                                                                                                   Das Unternehmen musste jetzt bei dem Potsdamer Amtsgericht Insolvenz anmelden   \n",
       "280                                                                                             Über die Gründe der Insolvenz konnte Unternehmenssprecher Johannes noch nichts sagen kündigte jedoch die Bekanntgabe weiterer Details für die Mitte dieser Woche an   \n",
       "324                                                                                                                 Die RegTP erteilte die Genehmigung weil ihr die bisher vorliegenden Daten nicht ausreichend erschienen um das abschließend beurteilen zu können   \n",
       "338                                                                                                                 Nutzer des können für Mark monatlich einschließlich und für normale Werktage an und Feiertagen kostenlos in dem gesamten deutschen telefonieren   \n",
       "365                                                                                                                                        Seit dem heutigen Mittwochmorgen kursierten an der Frankfurter Börse Gerüchte denen zufolge Ron Sommer zurücktreten wird   \n",
       "392                                                                                                                                               Letztlich dürfte es sich bei dem Gerücht lediglich um eine Begleiterscheinung der Talfahrt des Kurses der handeln   \n",
       "431                                                                                                                                                                                                         Der Nemax50 verlor seit heute Morgen knapp fünf Prozent   \n",
       "449                                                                                   Der Kölner Stadtnetzbetreiber NetCologne will mit Mannesmann Arcor einen Vertrag über den Zugang zu der Teilnehmeranschlussleitung der so genannten letzten Meile abschließen   \n",
       "475                                                                                                                                                                                   Weitere Details sollen erst an dem morgigen Donnerstag bekannt gegeben werden   \n",
       "584                                                                                                                                                                                                        Entsprechende Spekulationen gab es bereits seit längerem   \n",
       "709                              Die Bundesregierung spricht sich desweiteren dafür aus dass die Abgaben bei wegen der mehrfachen Überschreibbarkeit der Medien höher ausfallen sollten als bei da hier nur eine einmalige Vervielfältigungsmöglichkeit gegeben sei   \n",
       "816         Der Vergütungsbericht der Bundesregierung wird in Abständen in dem Auftrag des Bundestages erstellt um über die Entwicklung und Angemessenheit von Vergütungen nach 54 Urheberrechtsgesetz UrhG und insbesondere der Anlage zu 54 d 1 UrhG zu berichten   \n",
       "866                                      Geplant ist gleich eine ganze Serie von Spielen zu veröffentlichen die sich nach Aussage von Don Mattrick President der EA worldwide studios eng an den Romanvorlagen und an dem demnächst erscheinenden Harry orientieren   \n",
       "1021                                                                                                                       Grund für die Sperrung ist nach offiziellen Angaben dass auf diesen Seiten pornografisches Material und anderes Anstößiges zu finden sei   \n",
       "1052                                                                                                                                                                             Yahoo hat durch die Maßnahme jetzt in einem weiteren Land mit Problemen zu kämpfen   \n",
       "1116                                                                   Der Kopierschutz besteht nach Angaben von Intel aus einem das die sichere Verwaltung von Musik auf dem PC und deren Übertragung auf tragbare Audiogeräte und Speichermedien ermöglichen soll   \n",
       "1125                                                            Intels Softwarepaket soll die entscheidenden Codes Schlüssel und andere wichtige Informationen der vor dem Zugriff Dritter verbergen und Versuche erkennen den Sicherheitsmechanismus zu überwinden   \n",
       "1217                                                                                                                                                                            Der Messenger kommt für Linux in dem und umfasst gerade einmal knapp über 100 KByte   \n",
       "1271                                                                                                                                        Die Bonner Staatsanwaltschaft nahm wegen des Verdachts auf Kapitalanlagebetrug Ermittlungen gegen mehrere Vorstände auf   \n",
       "1520                                                                                                                                                                           Nach dem März können sich für flat den Pauschaltarif für und nicht mehr neu anmelden   \n",
       "1626                                                                                      Verbringt er in dem Monat weniger Stunden in dem Internet als er bezahlt hat so verfallen die restlichen Stunden surft er dagegen mehr kostet jede weitere Minute Pfennig   \n",
       "1671                                                                                                                                                                  Tiefrot waren die Zahlen die die Ende Januar auf der Bilanzpressekonferenz zu verkünden hatte   \n",
       "1805                                                                                                                                                Nicht die sind nach seinen Worten die größten Barrieren für den neuer Zielgruppen sondern die unverändert hohen   \n",
       "1871                                                                                                             Callahan übernimmt 55 Prozent der Anteile von der Deutschen Telekom und will das Kabelnetz für interaktives Fernsehen und einen schnellen ausbauen   \n",
       "2271                               Die die als 347 MByte großes gepacktes auf die Platte kommt enthält neben dem eigentlichen Linux noch den XMMS den Acrobat Reader den Macromedia Flash Player 4 einen Instant Messenger die eFax sowie den Netscape Communicator   \n",
       "2283                               Die die als 347 MByte großes gepacktes auf die Platte kommt enthält neben dem eigentlichen Linux noch den XMMS den Acrobat Reader den Macromedia Flash Player 4 einen Instant Messenger die eFax sowie den Netscape Communicator   \n",
       "2285                                                                                          Die die für knapp 25 auf CD bestellt werden kann bietet zusätzlich einen User Guide technischen Support per für 30 Tage sowie das Loki Entertainment Pack mit einigen   \n",
       "2419                                                                                                                                                                          Insgesamt arbeiten momentan noch rund 250 Mitarbeiter in der Dortmunder Niederlassung   \n",
       "2421                                                                                                                                                       Zukünftig will Versatel enger mit dem Tochterunternehmen KomTel in Flensburg zusammenarbeiten und nutzen   \n",
       "2558                                                                                                                                                                                                Mit dem türkischsprachigen Angebot steht aber nicht alleine dar   \n",
       "2722                                                                                                                                                                      Wenn da jetzt 5 Prozent Kunden anderer Provider hinzukämen würde das kaum etwas ausmachen   \n",
       "2738                                                                                                                                                             Wenn es also tatsächlich zu Engpässen kommen würde dann sei die Telekom schuld und niemand anderes   \n",
       "2780                                                                                             Wenn der VATM jetzt argumentiere dass die Provider zu hohe Kosten aufzuwenden hätten um eine bundesweite Flatrate anbieten zu können dann sei das so nicht richtig   \n",
       "3263                                                                                                                                                     Dass die Entscheidung des Gerichtes auch auf die Einstellung der zurückzuführen ist findet AOL bezeichnend   \n",
       "3838                                                                                Wie Ministeriumssprecher Michael Knaps gegenüber heise online sagte wollte die Mordkommission ein Forum auf einer Alfelder zu der Suche nach Hinweisen in einem Mordfall nutzen   \n",
       "3921  Dass Streamgate zu seinem Vorteil den Unmut all jener ausnutzen wollte die derzeit immer noch zu Hunderttausenden auf den bestellten warten und sich zudem durch die penetrante Robert Werbung veralbert fühlen dürften wird der Telekom nicht gefallen haben   \n",
       "3977                                                                                                                                                                       Enthalten ist darin ein Transfervolumen von 500 MByte jedes weitere GByte kostet 69 Mark   \n",
       "4046                                                                                                                                                                            Es sollen keine festen vergeben werden bei Inaktivität wird die Verbindung getrennt   \n",
       "4149                                                                                                                                                                                             Vorher waren bereits die Star Telecom und TelDaFax davon betroffen   \n",
       "4347                                                                                                                                                              Betroffen waren laut Clemens Gerth zirka Kunden die ihre über den Berliner Anbieter laufen lassen   \n",
       "4415                                                                                                                                                                                      Ein soll das Auslesen von und die Umwandlung der Songs in das ermöglichen   \n",
       "4427                                                                                                                                                                      Wer damit eine auslesen und auf die Festplatte kopieren wollte war auf das WMA angewiesen   \n",
       "4434                                                                                                                                                                                                           Ein weiteres soll das Abspielen von DVDs ermöglichen   \n",
       "4446                                                                                                                                                                          Das MP3 Creation Pack und das DVD Decoder Pack kann man unabhängig voneinander kaufen   \n",
       "4447                                                                                                                                                                          Das MP3 Creation Pack und das DVD Decoder Pack kann man unabhängig voneinander kaufen   \n",
       "4468                                                                                                                                Hierzu hatte das Unternehmen Anfang Mai die Voraussetzungen geschaffen und mit einen Vertrag über die Anmietung von geschlossen   \n",
       "4497                                                                                                    Schuld an der Verschiebung ist laut Kiyoyuki Tsujimura Managing Director von DoCoMo nicht das eigene Unternehmen Schuld seien die europäischen Netzanbieter   \n",
       "\n",
       "                word     hdt_lemma    pred_lemma  \n",
       "156          anderen       anderer         ander  \n",
       "159             mehr          mehr          viel  \n",
       "195            RegTP         RegTP         Regtp  \n",
       "263        Potsdamer     Potsdamer     potsdamer  \n",
       "280         weiterer          weit        weiter  \n",
       "324            Daten         Datum         Daten  \n",
       "338           können        können        Können  \n",
       "365      Frankfurter   Frankfurter   frankfurter  \n",
       "392          handeln       handeln       Handeln  \n",
       "431           Morgen        Morgen        morgen  \n",
       "449           Kölner        Kölner        kölner  \n",
       "475          Weitere          weit        weiter  \n",
       "584         längerem          lang         lange  \n",
       "709           Medien        Medium         Media  \n",
       "816             UrhG          UrhG          Urhg  \n",
       "866          Spielen         Spiel       Spielen  \n",
       "1021         anderes       anderer         ander  \n",
       "1052        weiteren          weit        weiter  \n",
       "1116              PC            PC            Pc  \n",
       "1125          andere       anderer         ander  \n",
       "1217           KByte         KByte         Kbyte  \n",
       "1271          Bonner        Bonner        bonner  \n",
       "1520            flat          flat          Flat  \n",
       "1626         weitere          weit        weiter  \n",
       "1671         Tiefrot       Tiefrot       tiefrot  \n",
       "1805           hohen          hoch           hoh  \n",
       "1871        ausbauen      ausbauen        Ausbau  \n",
       "2271           MByte         MByte         Mbyte  \n",
       "2283            eFax          eFax          Efax  \n",
       "2285              CD            CD            Cd  \n",
       "2419      Dortmunder    Dortmunder    dortmunder  \n",
       "2421       Zukünftig     Zukünftig     zukünftig  \n",
       "2558         alleine       alleine        allein  \n",
       "2722         anderer       anderer         ander  \n",
       "2738          schuld        schuld        Schuld  \n",
       "2780            hohe          hoch           hoh  \n",
       "3263  zurückzuführen  zurückführen  zurückzuführ  \n",
       "3838        Alfelder      Alfelder        alfeld  \n",
       "3921          warten        warten         Warte  \n",
       "3977           GByte         GByte         Gbyte  \n",
       "4046          festen          fest         Feste  \n",
       "4149       betroffen     betreffen     betroffen  \n",
       "4347        Berliner      Berliner      berliner  \n",
       "4415     ermöglichen   ermöglichen   Ermöglicher  \n",
       "4427      angewiesen      anweisen    angewiesen  \n",
       "4434        weiteres          weit        weiter  \n",
       "4446             MP3           MP3           mp3  \n",
       "4447             DVD           DVD           Dvd  \n",
       "4468     geschlossen     schließen   geschlossen  \n",
       "4497          DoCoMo        DoCoMo        Docomo  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fails_df = hdt_res[(hdt_res.hdt_lemma!=hdt_res.pred_lemma)&(hdt_res.hdt_lemma==hdt_res.spacy_lemma)].drop_duplicates(subset=['word','hdt_lemma'])\n",
    "fails_df.loc[~fails_df.pred_lemma.isna(),['sentence','word','hdt_lemma','pred_lemma']].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "216babeb-0337-439d-8038-4843a0a710c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glemma.glemma import GLemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90e72e6d-331f-4648-8493-5560bcb7c339",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = GLemma('../glemma/data', \n",
    "                    wordfreq_csv='../glemma/data/third-party/FrequencyWords/content/2018/de/de_full.txt',\n",
    "                    use_nouns_nbc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a7d9f2-71f4-458b-a266-0a5a738e4893",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
