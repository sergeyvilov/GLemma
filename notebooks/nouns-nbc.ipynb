{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5993c6a5-789a-4a55-a9e0-1146c318a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import StratifiedGroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "660e6697-2e84-4282-a72d-f78d890c5d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/nouns.json', 'rt', encoding='UTF-8') as json_file:\n",
    "    nouns = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4d8b953-5fb3-4c86-aa88-374e28d7393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wordfreq = pd.read_csv('data/third-party/FrequencyWords/content/2018/de/de_full.txt', sep=' ', names=['word','freq']).set_index('word').freq.sort_values(ascending=False)#sort by frequency\n",
    "#n_words_vocab = wordfreq.sum()\n",
    "#wordfreq = wordfreq.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18502f89-ef7b-4f4c-b82c-7be88a468fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = 100\n",
    "STATRULES_ACCURACY = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ee65a37-874c-4c45-8811-b4b56aa364f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_rule(wordform,lemma):\n",
    "\n",
    "        \n",
    "    for idx in range(min(len(wordform),len(lemma))):\n",
    "        if wordform[:idx+1]!=lemma[:idx+1]:\n",
    "            idx -= 1\n",
    "            break \n",
    "\n",
    "    seq_to_remove = wordform[idx+1:]\n",
    "    seq_to_add = lemma[idx+1:]\n",
    "    \n",
    "    rule = (seq_to_remove,seq_to_add)\n",
    "\n",
    "    assert re.sub(f'{seq_to_remove}$',seq_to_add,wordform)==lemma\n",
    "    \n",
    "    return rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3c9e81e-c4ce-4608-8484-8920f3dce023",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = []\n",
    "\n",
    "for wordform,lemmas in nouns.items():\n",
    "    for lemma_dict in lemmas:\n",
    "        lemma = lemma_dict['lemma']\n",
    "        rules.append((wordform,lemma,lemma_dict['genus'],lemma_dict['declination'], infer_rule(wordform,lemma)))\n",
    "\n",
    "rules = pd.DataFrame(rules,columns=['wordform', 'lemma', 'genus', 'declination', 'rule'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ab2b028-175c-46a9-a7ea-d87d9d3f49a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LAST = 6\n",
    "\n",
    "word_endings = []\n",
    "for idx in range(-N_LAST,0):\n",
    "    word_endings.append(rules.wordform.apply(lambda x:x[idx:]).rename(f'last_{abs(idx)}'))\n",
    "    #word_endings.append(rules.wordform.apply(lambda x:x[idx] if len(x)>=abs(idx) else '').rename(f'last_{abs(idx)}'))\n",
    "    \n",
    "word_endings = pd.concat(word_endings,axis=1)\n",
    "\n",
    "rules = pd.concat([word_endings,rules],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d23205eb-232c-4cc4-959d-fc5e3a8e7c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns_stat_rules = {}\n",
    "\n",
    "for idx in range(-N_LAST,0):\n",
    "    \n",
    "    feature = f'last_{abs(idx)}'\n",
    "    \n",
    "    feature_df = rules.groupby(feature).rule.value_counts(normalize=True).reset_index()\n",
    "    feature_counts = rules[feature].value_counts().rename('n_wordforms').reset_index()\n",
    "    \n",
    "    feature_df = feature_df.merge(feature_counts)\n",
    "    feature_df = feature_df[feature_df.n_wordforms>100]\n",
    "    \n",
    "    feature_df = feature_df[feature_df.proportion>STATRULES_ACCURACY].sort_values(by='n_wordforms',ascending=False)\n",
    "    \n",
    "    nouns_stat_rules[feature] = feature_df.set_index(feature).rule.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29d40fc1-2842-4bd8-8cf8-e78ade8a4028",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'data/nouns_stat_rules-{int(STATRULES_ACCURACY*100)}.pickle','wb') as f:\n",
    "    pickle.dump({'rules_dict':nouns_stat_rules, 'n_last':N_LAST}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "38bdfd9b-145a-4cef-8da0-f20e4827ccec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rule\n",
       "(, )             392682\n",
       "(en, )            85962\n",
       "(n, )             82390\n",
       "(s, )             72581\n",
       "(e, )             63237\n",
       "                  ...  \n",
       "(örner, orn)        165\n",
       "(öcher, och)        165\n",
       "(ännern, ann)       162\n",
       "(äste, ast)         162\n",
       "(ina, en)           160\n",
       "Name: count, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_counts = rules.rule.value_counts()\n",
    "\n",
    "class_counts = class_counts.iloc[:N_CLASSES]\n",
    "\n",
    "rules.loc[~rules.rule.isin(class_counts.index),'rule'] = '-'\n",
    "\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3b7fbc-f841-42c0-b39f-88461f7b31c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_enc = {rule:idx for idx,rule in enumerate(rules.rule.unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "88a4ee1d-fdd3-401a-bc2f-f83e4bc297ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['last_6',\n",
       " 'last_5',\n",
       " 'last_4',\n",
       " 'last_3',\n",
       " 'last_2',\n",
       " 'last_1',\n",
       " 'genus',\n",
       " 'connection']"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_encoder = OrdinalEncoder(handle_unknown='use_encoded_value',unknown_value=-2,encoded_missing_value=-1)\n",
    "\n",
    "features_list = rules.columns.drop(['lemma','wordform','rule']).tolist()\n",
    "\n",
    "features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "c4276022-a142-42e3-9b20-a4dbe4f67ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(820231, 8)"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = rules[features_list].values\n",
    "y = rules.rule.map(rules_enc).values\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "406d71bf-257b-427b-93cc-284611e86bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgkf = StratifiedGroupKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "8a210e4f-2760-4a17-8f11-2895c7616189",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (train_index, test_index) in enumerate(sgkf.split(X, y, rules.lemma)):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "21d3f7b7-e5fa-4ead-a597-b754928b8af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train  = X[train_index], y[train_index] \n",
    "X_test, y_test = X[test_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "fcbb2259-bf03-4e50-bda6-280da8c30790",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = features_encoder.fit_transform(X_train).astype(int)\n",
    "X_test = features_encoder.transform(X_test).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "6d4eca62-3fb7-4e91-958d-5342e944ca0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalNaiveBayes():\n",
    "\n",
    "    def __init__(self, kappa=2, epsilon=1e-20):\n",
    "        \n",
    "        self.kappa = kappa\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def _compute_priors_logprobs(self, y):\n",
    "\n",
    "        priors_probs = [class_counts/len(y) for class_counts in self.class_counts]\n",
    "\n",
    "        self.priors_logprobs = np.log(priors_probs)\n",
    "        \n",
    "    def _compute_loglikelihood(self, X, y):\n",
    "        \n",
    "        feature_counts = {feature_idx:np.zeros((self.n_categories[feature_idx]+2,self.n_classes)) for feature_idx in range(self.n_features)}\n",
    "        \n",
    "        for features, class_idx in zip(X, y):\n",
    "            \n",
    "            for feature_idx,feature_value in enumerate(features):\n",
    "                \n",
    "                feature_counts[feature_idx][feature_value,class_idx] += 1\n",
    "\n",
    "        loglikelihood = {feature_idx:np.zeros((self.n_categories[feature_idx]+2,self.n_classes)) for feature_idx in range(self.n_features)}\n",
    "\n",
    "        for feature_idx in range(self.n_features):\n",
    "            loglikelihood[feature_idx] = np.log((feature_counts[feature_idx]+self.epsilon)\n",
    "                                                          / (np.repeat(self.class_counts[None,...], self.n_categories[feature_idx]+2, axis=0)\n",
    "                                                            + self.kappa*self.epsilon))\n",
    "\n",
    "            loglikelihood[feature_idx][-1,:] = 0\n",
    "\n",
    "        self.loglikelihood = loglikelihood\n",
    "\n",
    "        \n",
    "    def fit(self, X_train, y_train, priors_logprobs=None):\n",
    "\n",
    "        counter = Counter(y_train)\n",
    "        \n",
    "        class_ids, class_counts = zip(*sorted(counter.items()))\n",
    "        \n",
    "        self.class_counts = np.array(class_counts)\n",
    "        self.n_classes = np.max(class_ids)+1\n",
    "\n",
    "        self.n_features = X_train.shape[1]\n",
    "        self.n_categories = X_train.max(axis=0)\n",
    "\n",
    "        if priors_logprobs is None:\n",
    "            self._compute_priors_logprobs(y_train)\n",
    "        else:\n",
    "            self.priors_logprobs = priors_logprobs\n",
    "\n",
    "        self._compute_loglikelihood(X_train, y_train)\n",
    "\n",
    "    def _get_bayes_numerator(self, X):\n",
    "\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        sample_loglikelihood = np.zeros((n_samples,self.n_features,self.n_classes))\n",
    "\n",
    "        for feature_idx in range(self.n_features):\n",
    "            \n",
    "            sample_loglikelihood[:,feature_idx,:] = self.loglikelihood[feature_idx][X[:,feature_idx]] #N_samplesxN_classes\n",
    "\n",
    "        numerator = sample_loglikelihood.sum(axis=1)  + self.priors_logprobs[None,...]\n",
    "\n",
    "        return numerator\n",
    "            \n",
    "    def predict_proba(self, X):\n",
    "\n",
    "        numerator = np.exp(self._get_bayes_numerator(X))\n",
    "        \n",
    "        probs = numerator/numerator.sum(axis=1,keepdims=True)\n",
    "                            \n",
    "        return probs\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        predicted_class_ids = self._get_bayes_numerator(X).argmax(1)\n",
    "\n",
    "        return predicted_class_ids\n",
    "        \n",
    "    def score(self, X, y):\n",
    "\n",
    "        y_pred = self.predict(X)\n",
    "\n",
    "        return (y_pred==np.array(y)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "20ea30e2-77be-49e7-8285-6078d7757a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pseudocount = 1\n",
    "\n",
    "#priors_df = rules.groupby('wordform').rule.value_counts(normalize=True).reset_index()\n",
    "\n",
    "#priors_df['wordfreq'] = priors_df.wordform.map(wordfreq)\n",
    "#priors_df.wordfreq = priors_df.wordfreq.fillna(0) + pseudocount\n",
    "#priors_df.wordfreq = priors_df.wordfreq/n_words_vocab\n",
    "#\n",
    "#rule_priors = priors_df.groupby('rule').apply(lambda x:(x.wordfreq*x.proportion).sum())\n",
    "#\n",
    "#rule_priors = rule_priors/rule_priors.sum()\n",
    "#\n",
    "#prior_logprobs = {rules_enc[rule]:np.log(rule_prob) for rule,rule_prob in rule_priors.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "41595ad3-33f0-4176-b212-ade48cabf69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbc = CategoricalNaiveBayes()\n",
    "\n",
    "nbc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "90213351-70c2-4994-9fd6-ed0c7d884e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9212313319110027"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbc.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "d6380d26-1292-4a95-8ea7-afd33ece9490",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = features_encoder.fit_transform(X).astype(int)\n",
    "\n",
    "nbc.fit(X_,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "935c7e6b-4569-4665-8af3-e2867dccbf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'data/nouns-nbc-top{N_CLASSES}.pickle','wb') as f:\n",
    "    pickle.dump({'clf':nbc,\n",
    "                   'features_encoder':features_encoder,\n",
    "                   'features_list':features_list,\n",
    "                   'rules_list':list(rules_enc.keys()),\n",
    "                   'n_last':N_LAST}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "ca302bac-95f5-402c-9839-0cd361860610",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NounsNBC():\n",
    "\n",
    "    def __init__(self, path):\n",
    "\n",
    "        with open(path,'rb') as f:\n",
    "\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "            self.nbc_clf = data['clf']\n",
    "            self.features_encoder = data['features_encoder']\n",
    "            self.features_list = data['features_list']\n",
    "            self.rules_list = data['rules_list']\n",
    "            self.n_last = data['n_last']\n",
    "        \n",
    "    def __call__(self, word, constraints=None):\n",
    "        \n",
    "        word_parts = [word[idx:] for idx in range(-self.n_last,0)]\n",
    "\n",
    "        if not constraints:\n",
    "            constraints = ((-1,-1),)\n",
    "\n",
    "        data = [word_parts+list(constraint) for constraint in constraints]\n",
    "\n",
    "        word_enc = self.features_encoder.transform(data).astype(int)\n",
    "        \n",
    "        if len(constraints)==1:\n",
    "\n",
    "            pred = self.nbc_clf.predict(word_enc)[0]\n",
    "            \n",
    "        else:\n",
    "                        \n",
    "            pred = self.nbc_clf.predict_proba(word_enc).mean(0).argmax()\n",
    "        \n",
    "        rule = self.rules_list[pred]\n",
    "    \n",
    "        if rule=='-':\n",
    "            return None\n",
    "        else:\n",
    "            seq_to_remove,seq_to_add = rule\n",
    "            return re.sub(f'{seq_to_remove}$',seq_to_add,word)\n",
    "            \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "54032bfe-1f7c-4113-b12f-4a89998bfed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbc = NounsNBC('data/nouns-nbc-top100.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "5cfb58d4-da45-4dfc-83ab-4031ecda2934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hhhwkeit'"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbc('hhhwkeiten',(('f','Nominativ Plural'),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc9057f-36b9-47e8-b214-301610a0ae1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
